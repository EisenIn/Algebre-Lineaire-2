\chapter{Valeurs propres}
\label{cha:valeurs-propres-et}


\section{Valeurs propres et vecteurs propres}
\label{sec:valeurs-propres-et}

\begin{definition}
  \label{def:16}
  Soit $V$ un espace vectoriel sur un corps $K$ et $f \colon V ⟶V$ un endomorphisme. Un \emph{vecteur propre} de $f$  associé à la \emph{valeur propre} $λ ∈K$ est un vecteur $v ≠ 0$ de $V$ tel que $f(v) = λ\,v$.
\end{definition}

\begin{example}
  \label{exe:23}
  Soit $f：V⟶V$, l'endomorphisme $f(v) = 0$ pour tous $v ∈V$. Alors tous vecteur $v∈V$ non-nul est un vecteur propre associé à $λ=0$. 
\end{example}


\begin{lemma}
  \label{lem:4}
  Soit $B = \{v_1,\dots,v_n\}$ une base de $V$ et $A ∈ K^{n×n}$ la matrice de l'endomorphisme $f : V ⟶V$ relative à $B$. La matrice $A$ est une matrice diagonale, c'est à dire $A$ est de la forme
  \begin{displaymath}
    A =
    \begin{pmatrix}
      λ_1  \\
         & \ddots \\
         & & λ_n
    \end{pmatrix},
  \end{displaymath}
  si et seulement si $v_i$ est un vecteur propre associé à la valeur propre $λ_i$ pour tout ${i\in\{1,\dots,n\}}$.
\end{lemma}

\begin{proof}
Pour $v ∈V$ soit $[v]_B ∈K^n$ le vecteur des coordonnées de $v$ relatif à $B$. On a $[f(v_i)]_B = A \,  [v_i]_B$ pour $i\in\{1,\dots,n\}$. Puisque $[v_i]_B = e_i$, et $f(v_i) = λ_i v_i$ alors
    \begin{displaymath}
      λ_i ⋅ e_i = A \, e_i, \text{ pour } i ∈\{1,\dots,n\}.
    \end{displaymath}
\end{proof}


\begin{definition}
  \label{def:39}
  Un endomorphisme $f ：V ⟶ V$ pour lequel il existe une base de $V$ composée de vecteurs propres est dit \emph{diagonalisable}. 
\end{definition}


\begin{definition}
  \label{def:40}
  Soit $A ∈ K^{n ×n}$ une matrice.
  Un \emph{vecteur propre} de $A$ associé à la \emph{valeur propre} $λ ∈K$ est un vecteur propre de l'endormophisme  $f(x) = Ax$ de $K^n$.
\end{definition}




\begin{example}
 \begin{enumerate}
 \item Soit $A = \left(\begin{array}{cc}
1 & 0 \\
0 & 0
\end{array}
\right) \in ℝ^{2 ×2}$. Alors
\begin{itemize}
 \item $v_1 = \left( \begin{array}{c} 1 \\ 0 \end{array} \right)$ est un vecteur propre associ\'e \`a la valeur propre $\lambda_1 = 1$,
 \item $v_2 = \left( \begin{array}{c} 0 \\ 1 \end{array} \right)$ est un vecteur propre associ\'e \`a la valeur propre $\lambda_2 = 0$,
 \item $v_3 = \left( \begin{array}{c} 1 \\ 1 \end{array} \right)$ n'est pas un vecteur propre.
\end{itemize}
\item Soit $A = \left(\begin{array}{cc}
\cos \phi & \sin \phi \\
-\sin\phi & \cos \phi
\end{array}
\right) \in ℝ^{2 ×2}$ pour $\phi \in ℝ$. \begin{itemize}
\item
Si $\phi\not=k\pi$, $k\inℕ$, alors $A$ n'a pas de valeur propre (r\'eelle).
\item Si $\phi = (2k+1)\pi$, $k\in ℕ$, alors $A =
\left(\begin{array}{cc}
-1 & 0 \\
0 & -1
\end{array}
\right)$ a une valeur propre $\lambda = -1$ et tous les vecteurs non-nuls $x\in ℝ^2$ sont des vecteurs propres associ\'es \`a $\lambda$.
\item Si $\phi = 2k \pi$, $k\in ℕ$, alors $A =
\left(\begin{array}{cc}
1 & 0 \\
0 & 1
\end{array}
\right)$ a une valeur propre $\lambda = 1$ et encore tous les vecteurs non-nuls $x\in ℝ^2$ sont des vecteurs propres associ\'es \`a $\lambda$.
\end{itemize}
On va voir que si on consid\`ere $A$ comme une matrice complexe, alors on a toujours les valeurs propres $\cos \phi + \iunit \sin \phi$ et $\cos \phi - \iunit \sin \phi$.
\end{enumerate}
\end{example}

\begin{lemma}
  \label{lem:21}
  Un vecteur $v ∈ V ⧹\{0\}$ est un vecteur propre de $f：V ⟶V$  associé à la valeur propre $λ ∈ K$ si et seulement si $v ∈ \ker(f - λ ⋅ \Id)$.
\end{lemma}



Rappel: L'endomophisme $\Id ： V ⟶V$ défini comme $\Id(v) = v$ pour tous $v∈ V$  est appelé l'\emph{identité}.

\begin{definition}
  \label{def:1}
  Soit $λ$ une valeur propre de l'endomorphisme $f：V ⟶V$. Le sous-espace $E_λ$ de $V$, défini comme
  \begin{displaymath}
    E_λ = \ker(f - λ ⋅ \Id)
  \end{displaymath}
  est appelé \emph{l'espace propre} de $f$ associé à $λ$. La dimension de $E_λ$ est dite \emph{la multiplicité géométrique de $λ$}.
\end{definition}

\begin{lemma}
  \label{elem:1}
  Soient $v_1,\dots,v_r ∈V$ des vecteurs propres, associés aux valeurs propres $λ_1,\dots,λ_r$ distinctes (c'est à dire $λ_i ≠ λ_j$ pour $i≠j$), alors  $\{v_1,\dots,v_r\}$ est un ensemble libre.
\end{lemma}

\begin{proof}
	Supposons que le lemme soit faux, alors soit $r≥1$ minimal, tel qu'il existent des vecteurs propres $v_1,\dots,v_r ∈V$  associés aux valeurs propres $λ_1,\dots,λ_r$ qui sont linéairement dépendants. Puisque $v_i ≠0$ pour tout $i \in \{1, \dots, n\}$ alors $r>1$.
  Considérons une combinaison linéaire non triviale
  \begin{equation}
    \label{eq:35}
    α_1 v_1 + \cdots + α_r v_r = 0.
  \end{equation}
  Puisque \eqref{eq:35} est un contre exemple minimal, on a $α_i≠0$ pour tout $i$. Nous pouvons supposer que $λ_r ≠0$. Autrement, on réarrange les termes de~\eqref{eq:35}. 

  Si on applique $f$ à l'expression \eqref{eq:35} on obtient
  \begin{displaymath}
    λ_1 α_1 v_1 + \cdots + λ_rα_r v_r = 0
  \end{displaymath}
  et en divisant par $λ_r$
  \begin{equation}
    \label{eq:37}
	 \frac{λ_1}{λ_r} α_1 v_1 + \cdots + α_r v_r = 0.
  \end{equation}

  On soustrait \eqref{eq:37} de \eqref{eq:35} et on obtient
  \begin{displaymath}
	  \left(1- \frac{\lambda_1}{\lambda_n}\right)α_1 v_1 + \cdots + \left(1- \frac{λ_{r-1}}{λ_r}\right)α_{r-1} v_{r-1} = 0.
  \end{displaymath}
  Donc $v_1, \dots, v_{r-1}$ sont linéairement indépendants, mais ceci est en contradiction avec la minimalité de $r$.
\end{proof}


\begin{corollary}
  \label{eco:1}
  Soit $f ：V ⟶V$ un endomorphisme d'un espace vectoriel $V$ sur $K$ de dimension $n ∈ ℕ^*$.
  Soient $λ_1,\dots,λ_r$ les valeurs propres distinctes de $f$
  et soient $n_1,\dots,n_r$ leurs multiplicités géométriques respectives.
  Soit $B_i= \{v_1^{(i)},\dots,v_{n_i}^{(i)}\}$ une base de $E_{λ_i}$ pour tout $i \in \{1,\dots,r\}$. Alors
  \begin{displaymath}
    \{ v_1^{(1)},\dots,v_{n_1}^{(1)},v_1^{(2)},\dots,v_{n_2}^{(2)},\cdots,v_1^{(r)},\dots,v_{n_r}^{(r)} \}
  \end{displaymath}
est un ensemble libre et $f$ est diagonalisable si et seulement si
\begin{displaymath}
  n_1 + \cdots + n_r =n.
\end{displaymath}
\end{corollary}
\begin{proof}
	Soient $\alpha_{ij} \in K$ pour $i \in \{1, \dots, r\}, j \in \{1, \dots, n_i\}$ tels que
  \begin{displaymath}
    ∑_{i=1}^r ∑_{j=1}^{n_i} α_{ij} v^{(i)}_j = 0,
  \end{displaymath}
  alors selon le Lemme~\ref{elem:1}, $\left\{∑_{j=1}^{n_i} α_{ij} v^{(i)}_j\right\}_{i = 0}^r$ est un ensemble libre et donc pour tout $i$, $\sum_{j=1}^{n_i} α_{ij} v^{(i)}_j = 0$. Or $v_1^{(i)},\dots,v_{n_i}^{(i)}$ son linéairement indépendants, et donc les termes $a_{ij}$ sont tous égaux à $0$. Ainsi
   \begin{displaymath}
    \{ v_1^{(1)},\dots,v_{n_1}^{(1)},v_1^{(2)},\dots,v_{n_2}^{(2)},\cdots,v_1^{(r)},\dots,v_{n_r}^{(r)} \}
  \end{displaymath} est un ensemble libre. En plus, si $n_1+\cdots+n_r=n$, c'est une base de $V$ et donc $f$ est diagonalisable.

  Réciproquement, si $f$ est diagonalisable, et si $m_i$ dénote le nombre de vecteurs propres dans $E_{λ_i}$ qui appartiennent à la base consistant de vecteurs propres, alors $m_i ≤ n_i$ et donc on a
  \begin{displaymath}
    n = m_1 + \cdots + m_r ≤ n_1+ \cdots + n_r ≤n,
  \end{displaymath}
  alors $n_1+\cdots + n_r =n$.
\end{proof}




Ceci nous donne un marche à suivre pour déterminer si $f：V ⟶V$ est diagonalisable.

\begin{enumerate}
\item Déterminer les différents $λ_1,\dots,λ_r ∈K$ tels que $\ker(f - λ \Id) ≠ \{ 0 \}$
\item Pour chaque $λ_i$ calculer une base $\{v_1^{(i)},\dots,v_{n_i}^{(i)}\}$ de $E_{λ_i}$.
\item $f$ est diagonalisable si et seulement si  $n_1+\cdots+n_r =n$.
\end{enumerate}





\subsection*{Exercices}

\begin{enumerate}
\item Une matrice $A ∈ K^{n ×n}$ est appelée \emph{diagonalisable},  si endomorphisme $φ：K^n ⟶K^n$ défini comme $φ(x) = Ax$ est diagonalisable. Démontrer que $A$ est diagonalisable, si et seulement s'il existe $U ∈ K^{n×n}$ inversible tel que $U^{-1} A U$ est une matrice diagonale. \label{item:18}
\end{enumerate}

\section{Le polynôme caractéristique}
\label{sec:le-polyn-caract}

Durant ce chapitre nous allons étudier les endomorphismes $f：V⟶V$ d'un espace vectoriel de dimension fini $n ∈ ℕ$.  Si  $B = \{v_1,\dots,v_n\}$ est une base de $V$, on a
\begin{displaymath}
  f(x) = \phi_B^{-1} (A_B \phi_B(x)),
\end{displaymath}
où $\phi_B$ est l'ismomorphisme $\phi_B \colon V \longrightarrow K^n$, $\phi_B(x) = [x]_B$ sont les coordonnées de $x$ par rapport à la base $B$. On a le diagramme suivant
\begin{displaymath}
  {
  \begin{CD}
    V     @>f>>  V\\
    @VV \phi_B V        @VV \phi_B V\\
    K^n     @>A \cdot x>>  K^n
  \end{CD}}
\end{displaymath}
Les colonnes de la matrice $A_B$ sont les coordonnées de $f(v_1),\dots,f(v_n)$ dans la base $B$. Si $B'$ est une autre base de $V$ on a
\begin{displaymath}
  [x]_{B'} = P_{BB'}[x]_B,
\end{displaymath}
où $P_{BB'}$ est la matrice de changement de base de $B$ en $B'$. Puisque
\begin{displaymath}
  [f(v)]_{B'} = A_{B'} [v]_{B'} = A_{B'} P_{BB'}[v]_B
\end{displaymath}
et
\begin{displaymath}
  [f(v)]_{B'} =  P_{BB'}[f(v)]_B,
\end{displaymath}
on trouve
\begin{displaymath}
  [f(v)]_B =  P_{BB'}^{-1}A_{B'} P_{BB'}[v]_B \,\,\,\text{ pour tous } v ∈V.
\end{displaymath}
Ceci implique 
\begin{equation}
  \label{eq:36}
  A_{B} =  P_{BB'}^{-1} A_{B'}  P_{BB'}.
\end{equation}
En particulier,
\begin{displaymath}
	\det(A_{B'}) = \det(A_B). 
\end{displaymath}
On définit le \emph{déterminant d'un endomorphisme} $f$ par $\det(f) := \det(A_B)$. 



Clairement, $λ$ est une valeur propre de $f$ si et seulement si $λ$ est une valeur propre de $A_B$ et c'est le cas si et seulement si
\begin{equation}
  \label{eq:30}
  \det(A_B - λ I_n) = 0.
\end{equation}



On rappele la formule de Leibniz pour le determinant d'une matrice $B ∈ K^{n ×n}$:
\begin{equation}
  \label{eq:31}
  \det(B)  = ∑_{π ∈S_n} \sign(π) ∏_{i=1}^n b_{iπ(i)}.
\end{equation}
Si on collecte les puissances de $λ$, alors on obtient
\begin{equation}
  \label{eq:32}
  \det(A_B - λI_n) = a_n λ^n + a_{n-1} λ^{n-1}+ \dots + a_1 λ+ a_0
\end{equation}
où $a_n,\dots,a_0 ∈K$. Puisque $\det(A_B) = \det(A_B - 0 ⋅ I_n)$, alors $a_0 = \det(A_B)$.
\begin{definition}
  \label{def:50}
  Le polynôme $\det(A_B - λI_n) ∈ K[λ]$ est appelé le \emph{polynome caractéristique} de $f$.   
\end{definition}

\begin{remark}
  \label{rem:6}
  Soient $B$ et $B'$ deux bases, alors puisque $A_{B} =  P_{BB'}^{-1} A_{B'}  P_{BB'}$, on obtient
  \begin{eqnarray*}
    \det(A_B - λI_n) & = & \det(P_{BB'}^{-1} A_{B'}  P_{BB'} - λP_{BB'}^{-1}I_n  P_{BB'}) \\
                     & = & \det(P_{BB'}^{-1}) \det(A_{B' }- λI_n) \det(P_{BB'}) \\
     & = & \det(A_{B' }- λI_n),
  \end{eqnarray*}
  c.à.d. le polynôme de la Définition~\ref{def:50} est bien défini en fonction de $f$.  
\end{remark}


\subsection{Polynômes}
\label{sec:polynomes}
Soit $K$ un corps et soit $x$ un nouveau élément qui n'appartient pas à $K$. Nous considérons les expressions
\begin{equation}
  \label{eq:33}
  p(x) = a_0 + a_1 x + \cdots + a_n x^n
\end{equation}
où $a_i ∈K$ pour $i\in\{1,\dots,n\}$ et $x$ est une \emph{indéterminée} ou une  \emph{variable}.
D'un point de vue formel, $x ∈ R ⧹K$, où $R⊃K$ est un anneau intègre, tel que
\begin{displaymath}
  a_0+ a_1x + \cdots + a_n x^n =0, \, a_i ∈K, \text{ implique } a_i=0 \text{ pour tous }i.  
\end{displaymath}
L'existence de $R$ et $x$ est traité en détail dans le cours \emph{anneaux et corps}. 
L'élément $a_i$ est le $i$-ème coefficient de $p(x)$. Le polynôme $p(x)$ est écrit comme
\begin{displaymath}
  p(x) = a_0 + a_1x + a_2x^2 + \cdots
\end{displaymath}
où tous les  coefficients, sauf un nombre fini parmi eux, sont zéro.
Des expressions de la forme \eqref{eq:33} sont des polynômes sur $K$. On note $K[x]$ est l'ensemble des polynômes sur $K$. Deux polynômes
\begin{equation}
  \label{eq:34}
  p(x) = a_0 + a_1x + a_2x^2 + \cdots \,\,\text{ et }  \,\, q(x) = b_0 + b_1x + b_2x^2 + \cdots
  \end{equation}
  sont \emph{égaux} si $a_i  =b_i$ pour tous $i$. Dans ce cas, on écrit $p(x) = q(x)$.
La \emph{somme} de $p(x)$ et $q(x)$~\eqref{eq:34} est le polynôme
\begin{displaymath}
  p(x) + q(x)  = a_0+b_0 + (a_1+b_1)x + (a_2+b_2)x^2 + \cdots
\end{displaymath}
et leurs \emph{produit} est
\begin{equation}
  \label{ceq:21}
  p(x) ⋅q(x) = a_0 b_0 + (a_0b_1 +a_1b_0) x + (a_0b_2+ a_1b_1 + a_2b_0)x^2 + \cdots .
\end{equation}
Le $i$-ème coefficient de $p(x)⋅q(x)$ est alors  $∑_{j+k=i}a_jb_k$.

\begin{theorem}
  \label{thr:43}
  L'ensemble des polynômes $K[x]$ sur un corps $K$ est un anneau intègre.
\end{theorem}

\begin{definition}
	Le \emph{degré} de $p(x) = a_0 + a_1x + a_2x^2 + \cdots \neq 0$ est 
	\begin{displaymath}
	  \deg(p) = \max\{i \colon  a_i \neq 0\}
	\end{displaymath}
	et $\deg(0) = -\infty$. 
	Si $p \neq 0$, le coefficient $a_{\deg(p)}$ est le \emph{coefficient dominant} de $p$. 
	Un polynôme de degré zéro est une \emph{constante}. 
\end{definition}

\begin{theorem}
  \label{thr:34}
  Pour $f,g \in K[x] $, $\deg(f \cdot g) = \deg(f) + \deg(g)$. 
\end{theorem}
\begin{proof}
  La formule~\eqref{ceq:21} révèle que $\deg(f\cdot g) \leq \deg(f) + \deg(g)$. 
  Soient $f(x) = a_0 + \cdots + a_n x^n$ et $g(x) = b_0+ \cdots b_m x^m$ tels que $a_n, b_m  \neq 0$. Le coefficient de $x^{n+m}$  est $a_n \cdot  b_m \neq 0$.
\end{proof}

Un polynôme $p(x) = a_0 + a_1 x + \cdots + a_n x^n ∈ K[x]$ induit une application $f_p:  K ⟶ K$, $f_p(k) = a_0+ a_1 k+ \cdots + a_n k^n$. Nous écrivons aussi $p(k)$ pour $f_p(k)$.  

\begin{theorem}
  \label{thr:42}
  Soit $K$ un corps infini. Deux polynômes $p(x),q(x) ∈ K[x]$ sont égaux, si et seulement si les applications $f_p$ et $f_q$ sont les mêmes.
\end{theorem}

La démonstration du théorème~\ref{thr:42} est le premier exercice maison.  

\begin{definition}
  \label{def:31}
  Soit $p(x) \in K[x] \setminus\{0\}$. Un $\alpha \in K$ tel que $f_p(\alpha) = 0$ est une  \emph{racine} de $p(x)$.  
\end{definition}


\begin{theorem}[Théorème fondamental de l'algèbre]
  \label{thr:44}
  Tout polynôme $p(x) ∈ℂ[x] ⧹\{0\}$ de degré aux moins $1$ admet au moins une racine complexe.
\end{theorem}


L'expression \eqref{eq:32} est un polynôme avec l'indéterminée $λ$ et comme polynôme formel, est défini par la formule de Leibniz
\begin{displaymath}
p_A(λ) = \det(A - λ I_n) = ∑_{π ∈S_n} \sign(π) ∏_{i=1}^n (A - λ I_n)_{iπ(i)}.
\end{displaymath}
Il est la somme des polynômes $ \sign(π) ∏_{i=1}^n (A - λ I_n)_{iπ(i)}$ avec $\pi \in S_n$. Ça démontre que le degré de $p_A(λ)$ est au plus $n$. Mais pour $\pi = \Id$, le degré de
\begin{displaymath}
  \sign(\Id) ∏_{i=1}^n (A - λ I_n)_{i\Id(i)}
\end{displaymath}
est $n$ exactement. En particulier, $\Id$ est la seulle permutation dans $S_n$ telle que le produit est un polynôme de degré $n$. Ainsi $a_n = (-1)^n$.

\begin{lemma}
  \label{lem:22}
Soit $p_A(λ) = a_0 + a_1 λ + \cdots + a_n λ^n$ le polynôme caractéristique de la matrice $A ∈ K^{n ×n}$. Alors, $a_0 = \det(A)$ et $a_n = (-1)^n$.
\end{lemma}


\begin{corollary}
  \label{co:10}
  Soit $V ≠ \{0\}$ un espace vectoriel de dimension fini sur $K = ℂ$, et $f: V → V$ un endomorphisme. Alors $f$ possède une valeur propre. 
\end{corollary}
\begin{proof}
  Soit $f(λ) ∈ ℂ[λ]$ le polynôme caractéristique de $f$ et $n$ la dimension de $V$. Le degré de $f$ est égal à $n≥1$, alors $p(x)$ possède une racine $λ^* ∈ℂ$. Cette racine $λ^*$  est une valeur propre de $f$. 
\end{proof}

Dans le theorème qui suit on définit la division des polynômes avec reste.

\begin{theorem}
  \label{thr:33}
  Soient $f,g \in K[x]$ et $\deg(g) >0$. Il existe des uniques $q,r \in K[x]$ tels que 
  \begin{displaymath}
    f(x) = q(x) g(x) + r(x) 
  \end{displaymath}
  et $\deg(r) < \deg(g)$. 
\end{theorem}


\begin{proof}
	On montre l'existence par récurrence sur $\deg(f)$. Si $\deg(f) < \deg(g)$, alors on pose $q = 0$ et $r = f$ et on a fini.

Supposons alors $\deg(f) = n \geq \deg(g)=m$ et 
\begin{displaymath}
  f(x) = a_0+ \cdots +a_n x^n \text{ et } g(x) = b_0 + \cdots + b_m x^m 
\end{displaymath}
où $a_n$ et $b_m$ sont les coefficients dominants de $f$ et $g$ respectivement. 
Clairement 
\begin{displaymath}
  \deg\left( f(x) - \frac{a_n}{ b_m } x^{n-m} g(x) \right) < \deg(f(x))
\end{displaymath}
et par l'hypothèse de récurrence il existe $q, r \in K[x]$ tels que
\begin{displaymath}
  f(x) - \frac{a_n}{ b_m } x^{n-m} g(x)  = q(x) g(x) + r(x) 
\end{displaymath}
et $\deg(r(x)) < \deg(g(x))$. On  obtient alors
\begin{displaymath}
  f(x) = \left(q(x) + \frac{a_n}{ b_m } x^{n-m} \right) g(x) + r(x). 
\end{displaymath}

Montrons l'unicité de $q$ et $r$. Supposons qu'il existe deux autres polynômes $q'(x)$ et $r'(x)$ tels que 
\begin{displaymath}
    f(x) = q'(x) g(x) + r'(x) 
  \end{displaymath}
  et $\deg(r') < \deg(g)$. 
Alors 
\begin{displaymath}
0 \neq   r(x) - r'(x) = (q(x) - q'(x)) ⋅ g(x). 
\end{displaymath}
Mais ceci implique 
\begin{displaymath}
\max\{\deg(r),\deg(r')\} \geq   \deg( r - r')  = \deg(q - q') + \deg(g) \geq \deg(g), 
\end{displaymath}
ce qui contredit le fait que $\deg(r) < \deg(g)$ et $\deg(r') < \deg(g)$. 
\end{proof}


% \begin{definition}
%   Pour $f(x)  = a_0 + \cdots + a_n x^n \in K[x]$ et $\alpha \in K$, l'évaluation $f(\alpha)$ est $ a_0 + a_1 \alpha + \cdots + a_n \alpha^n \in K$. 
% \end{definition}


\begin{example}
  \label{exe:24}
  Faire la division avec reste des polynômes  $x^5+2x^2+1$ par $2x^3+x+1$ de $ℤ_3[x]$ 
\end{example}

%\begin{proposition}
%  \label{prop:5}
%  Pour $\alpha \in K$, $\phi_\alpha: \, K[x] \longrightarrow K$, %$\phi_\alpha(f(x)) = f(\alpha)$ est un homomorphisme.  
%\end{proposition}


\begin{definition}
  \label{def:32}
  Un polynôme  $q(x) ∈K[x]$ \emph{divise} un  polynôme $f(x)∈ K[x]$ s'il existe un polynôme $g(x)$ tel que $f(x) = g(x) \cdot q(x)$. On dit que $q(x)$ est un diviseur de $f(x)$ et on écrit $q(x) \mid f(x)$. 
\end{definition}

\begin{theorem}
  \label{thr:35}
  Soit $f(x)∈ K[x] \setminus \{0\}$ un polynôme  et $\alpha \in K$, alors $\alpha$ est une racine de $f$ si et seulement si $(x- \alpha)  \mid f(x)$. 
\end{theorem}

\begin{proof}
  Si $f(x) = q(x) \cdot (x - \alpha)$, alors $f(\alpha) = 0$. 

%Autrement, si $f$ est une constante, $f = 0$ et $(x - \alpha)$ divise $f$.
Dans l'autre sens, si $f$ est une constante, $f(\alpha) = 0$ implique que $f = 0$ et $(x - \alpha)$ divise $f$. 

Si $f$ n'est pas une constante, il existe $q(x)$ et $r(x)$ tels que
\begin{displaymath}
  f(x) = q(x) \cdot (x - \alpha) + r(x)
\end{displaymath}
%$\deg(r) = 0$. Alors $f(\alpha) = 0$ implique $r=0$. 
avec $\deg(r) \leq 0$. Alors $f(\alpha) = 0$ implique $r=0$. 
\end{proof}


\begin{definition}
  \label{def:41}
  La \emph{multiplicité} d'une racine $α$ de $p(x) ∈ K[x] ⧹\{0\}$ est le plus grand $i≥1$ tel que $ (x-α)^i \mid p(x)$. Si $p(x)$ est le polynôme caractéristique d'un endomorphisme d'un espace vectoriel, on appelle la multiplicité de $α$ la \emph{multiplicité algébrique}. 
\end{definition} 



\begin{theorem}[Théorème de diagonalisation]
  \label{thr:45}
  Soit $V$ un espace vectoriel sur $K$ de dimension $n$, $f:V⟶V$  un endomorphisme et $λ_1,\dots,λ_r ∈ K$ les valeurs propres distinctes de $f$.    Alors $f$ est diagonalisable si et seulement si 
  \begin{enumerate}[i)]
  \item le polynôme caractéristique $p_f(x)$ de $f$ se décompose en facteurs linéaires, c'est à dire, \label{item:19} 
    \begin{displaymath}
      p_f(x) = (-1)^n ∏_{i=1}^r (x - λ_i )^{g_i}
    \end{displaymath}
    où $g_i$ est la multiplicité algébrique de $λ_i∈K$ pour tous $i$. 
    \item  $\dim(E_{λ_i}) = g_i$, pour tous $i=1,\dots,r$. C'est à dire, les multiplicités algébriques et géométriques sont les mêmes. \label{item:20}
  \end{enumerate}
\end{theorem}

\begin{proof}
  Supposons $f$ diagonalisable. Soit $B$ une base composé de vecteurs propres de $f$ et $A$ la matrice de $f$ associé à la base $B$. Le Lemme~\ref{lem:4} implique que $A$ est diagonale et alors  $p_f(x) = \det(A - x \Id) = (-1)^n ∏_{i=1}^r (x - λ_i)^{g_i}$. La dimension de $E_{λ_i}$ est celle du $\ker(A - λ_i I_n)$. Et clairement $\dim(\ker(A - λ_i I_n)) = g_i$. Alors on a \ref{item:19}) et \ref{item:20}).


  Si  on a \ref{item:19}) et \ref{item:20}), soient $m_i$ les multiplicités géométriques des valeurs propres $λ_i$, $i=1,\dots,r$. Puisque
  \begin{displaymath}
    \deg((-1)^n∏_{i=1}^n (λ_i -x)^{g_i} =n,
  \end{displaymath}
  alors $m_1 + \cdots + m_r = n$ et en invoquant le Corollaire~\ref{eco:1} on déduit que $f$ est diagonalisable. 
\end{proof}



\begin{example}
  \label{exe:30}
  Soit $f： ℝ^3 → ℝ^3$ donnée par
  \begin{displaymath}
      f(x) = Ax, \, \text{ où }      A =  \begin{pmatrix}
        0 & -1 & 1 \\
        -3 & -2 & 1 \\
        -2 & -2 & 3
      \end{pmatrix}      
    \end{displaymath}
    Pour la base canonique  $B = \{e_1,e_2,e_3\}$ de $ℝ^3$, on a $A_B =A$. Le polynôme caractéristique de $f$ est
    \begin{displaymath}
      p(x) = -x^3 + x^2 + x -1 = - (x-1)^2 (x+1). 
    \end{displaymath}
    Les valeurs propre de $f$ sont $λ_1 = 1$ et $λ_2 = -1$ et
    \begin{displaymath}
      \left\{
          \begin{pmatrix}
            1 \\ 0 \\1
          \end{pmatrix},
          \begin{pmatrix}
            0 \\ 1 \\ 1
          \end{pmatrix} \right\} \text{ et }  \left\{
          \begin{pmatrix}
            1 \\ 3 \\2
          \end{pmatrix} \right\}
    \end{displaymath}
    sont des bases de $E_{λ_1}$ et  $E_{λ_2}$  respectivement. Alors $f$ est diagonalisable et pour la base
    \begin{displaymath}
      B' =  \left\{
          \begin{pmatrix}
            1 \\ 0 \\1
          \end{pmatrix},
          \begin{pmatrix}
            0 \\ 1 \\ 1
          \end{pmatrix}, 
          \begin{pmatrix}
            1 \\ 3 \\2
          \end{pmatrix} \right\}   
    \end{displaymath}
    on a
    \begin{displaymath}
      A_{B'} =
      \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & -1 
      \end{pmatrix}
    \end{displaymath}
    et
    \begin{displaymath}
      P_{BB'} = \left(\begin{matrix}1 & 0 & 1\\0 & 1 & 3\\1 & 1 & 2\end{matrix}\right)^{-1} 
    \end{displaymath}
    On peut vérifier 
\begin{equation}
  A_{B} =  P_{BB'}^{-1} A_{B'}  P_{BB'}. 
\end{equation}

    
  \end{example}

  \begin{proposition}
    \label{prop:6}
    Soit $f： V → V$ un endomorphisme et soit $λ ∈K$ une valeur propre de $f$. Alors la multiplicité géométrique de $λ$ est au plus la multiplicité algébrique de $λ$. 
  \end{proposition}

  \begin{proof}
    Soit $m$ la multiplicité géométrique de $λ$ et soit  $\{v_1,\dots,v_m\}$  und base de $E_{λ}$. On peut augmenter cette base de $E_{λ}$ à une base
    \begin{displaymath}
B =     \{ v_1,\dots,v_m, w_1,\dots,w_{n-m}\} 
    \end{displaymath}
    de $V$.

    La matrice $A_B$ est de la forme
    \begin{displaymath}
      A_B =
      \begin{pmatrix}
        λ I_m & C \\
        0 & D
      \end{pmatrix}
    \end{displaymath}
    où $C ∈ K^{m × n-m}$ et $D ∈ K^{(n-m) ×(n-m)}$.
    Le polynôme caractéristique $p(x) ∈ K[x]$ de $f$ est
    \begin{eqnarray*} p(x) & = &  
      \det   \begin{pmatrix}
        (λ -x) I_m & C \\
        0 & D-xI_{n-m}
      \end{pmatrix} \\
          & = & (λ -x)^m \det \left(D-xI_{n-m}\right). 
    \end{eqnarray*}
    Alors la multiplicité algébrique de $λ$ est au moins $m$. 
  \end{proof}
  
\subsection*{Exercices}

\begin{enumerate}
\item Donner un exemple d'un corps fini $K$ et deux polynomes $p(x) ≠q(x) ∈ K[x]$ tel que $f_p=f_q$.
\end{enumerate}

\section{Matrices semblables}
\label{sec:matrices-semblables}

\begin{definition}
  \label{def:42}
  Deux matrices $A,B ∈K^{n×n}$ sont \emph{semblables}, s'il existe une matrice inversible $P ∈ K^{n ×n}$ tel que $A = P^{-1} ⋅B ⋅P$.  
\end{definition}
L'équation~\eqref{eq:36} montre que les matrices $A_B$ et $A_{B'}$ d'un endomorphisme $f：V⟶V$ sont semblables, où $B$ et $B'$ sont deux bases de $V$ respectivement.

\begin{definition}
  \label{def:43}
  L'ensemble des valeurs propres d'une matrice $A ∈ K^{n ×n}$ (d'un endomorphisme $f：V ⟶V$) est appelé le \emph{spectre} de $A$ (de $f$), noté $\spec(A)$ ($\spec(f)$). 
\end{definition}

\begin{theorem}
  \label{thr:46}
  Soit $A ∈ K^{n ×n}$ une matrice et $P ∈ K^{n ×n}$ une matrice inversible.
  \begin{enumerate}[i)]
  \item Le spectre de $A$ et celui de $P^{-1}AP$ sont les mêmes.
  \item $v ∈ K^n$ est un vecteur propre de $A$ si et seulement si $P^{-1} v$  est un vecteur propre de $P^{-1}AP$.
  \item Les polynômes caractéristiques $p_A(x)$ et $p_{P^{-1}AP}(x)$ sont identiques. 
  \end{enumerate}
\end{theorem}


\section{Théorème de Hamilton-Cayley}
\label{sec:theoreme-de-hamilton}


Soit $A ∈ K^{n ×n}$ et $p(x) = a_0 + a_1x + \cdots + a_n x^n ∈ K[x] ⧹\{0\}$ un polynôme. On peut évaluer le polynôme à la matrice $A$ comme ci-dessous
\begin{displaymath}
  p(A) = a_0 ⋅I_n + a_1 A + \cdots + a_n A^n ∈ K^{n ×n}. 
\end{displaymath}
Maintenant, soit $p_A(x)$ le polynôme caractéristique de $A$ et $v$ un vecteur propre de $A$ associé a la valeur propre $λ$. On voit que
\begin{displaymath}
  p_A(A) ⋅v = a_0 v + a_1 λv + \cdots + a_n λ^n v = p_A(λ)v = 0 ⋅v = 0. 
\end{displaymath}
Alors, si $A$ est diagonalisable, il existe B = $\{v_1,\dots,v_n\}$ une base de vecteurs propres. Puisque $p_A(A)⋅v_i = 0$ pour tous $v$, alors $p_A(A)\cdot v=0$ pour tout $v \in V$ et donc $p_A(A) = 0$.

\begin{theorem}[Hamilton-Cayley] 
  \label{thr:47}
  Soit $A ∈ K^{n ×n}$ et $p_A(λ)$ le polynôme caractéristique de $A$, alors
  \begin{displaymath}
    p_A(A) =0.
  \end{displaymath}
\end{theorem}
\begin{proof}
 On écrit
  \begin{displaymath}
    \det(A - λI_n) I_n = \cof(A - λI_n)^T (A - λI_n).
  \end{displaymath}
  En regroupant les coefficients de $λ^i$ dans l'expression pour $\cof(A - λI_n)^T$ on obtient
  \begin{displaymath}
    \cof(A - λI_n)^T = ∑_{i=0}^{n-1} λ^i B_i
  \end{displaymath}
  avec des matrices $B_i ∈K^{n ×n}$ et alors
  \begin{displaymath}
    a_0 I_n + a_1 λ I_n + \cdots + a_nλ^n I_n  = B_0A + ∑_{i=1}^{n-1}λ^i (B_iA - B_{i-1}) - λ^n B_{n-1},
  \end{displaymath}
  où $p_A(λ) = a_0+ \cdots + a_n λ^n$. Ceci implique
  \begin{equation}
    \label{eq:38}
    \begin{array}{rcl}
      a_0 I_n & = &  B_0A \\
      a_iI_n & = &  B_iA - B_{i-1} \text{ pour } i ∈  \{1,\dots,n-1\}\\
      a_n I_n & = & - B_{n-1}
    \end{array}
  \end{equation}
  Si on multiplie les lignes contenant $a_i$ à droite par par $A^i$, on obtient:
  \begin{equation}
    \label{eq:38b}
	 \begin{array}{rcl}
      a_0 I_n & = &  B_0A \\
		a_iA^i & = &  B_iA^{i + 1} - B_{i-1}A^i \text{ pour } i ∈  \{1,\dots,n-1\}\\
      a_n A^n & = & - B_{n-1}A^n
    \end{array}
  \end{equation}
  Et finalement en sommant les termes on obtient $p_A(A) = 0$.

\end{proof}





\begin{example}
Le polyn\^ome caract\'eristique de $A = \left( \begin{array}{cc} 1 & 1 \\ 0 & 2
\end{array} \right)$ est $p_A(t) = (1-t)(2-t)$. On a 
\[
 p_A(A) = (I_n-A)(2I_n-A) = 0 
\]
Pour la matrice $A = \left( \begin{array}{cc} 2 & 0 \\ 0 & 2 \end{array}
\right)$, on a bien sur que $p_A(A) = 0$ pour $p_A(t) = (2-t)^2$. Mais il existe un polyn\^ome de degr\'e $1$, $q(t) = t-2$, tel que $q(A) = 0$. Le \emph{polyn\^ome minimal} de $A$
est le polyn\^ome unitaire de degr\'e minimal parmi ceux qui annulent $A$, c-\`a-d $q(A) = 0$. Nous examinerons de plus près le polyn{\^o}me minimal du chapitre~\ref{sec:polyn-les-lalg}.
\end{example}

Les resultats suivants donnent des utilisations typiques du théorème~\ref{thr:47}

\begin{samepage}
\begin{corollary} Soit $A \in K^{n ×n}$.
	\begin{enumerate}
		\item[(i)] Toute puissance $A^k$ avec $k∈ℕ$ peut s'\'ecrire comme une combinaison lin\'eaire des puissances $I,A,A^2,\ldots,A^{n-1}$.
		\item[(ii)] Si $A$ est inversible, alors l'inverse $A^{-1}$ peut s'\'ecrire comme une combinaison lin\'eaire des puissances $I,A,A^2,\ldots,A^{n-1}$.
	\end{enumerate}
\end{corollary}
\end{samepage}

\begin{proof}
 (i). Trivialement, l'assertion est vraie pour $k = 0,1,\ldots,n-1$.
On montre le cas $k = n$. Par le théorème~\ref{thr:47}:
\[
 0 = p_A(A) = \alpha_0 I + \alpha_1 A  \cdots + \alpha_{n-1} A^{n-1} + \alpha_n A^n \quad
\Rightarrow \quad A^n = 
-\frac{\alpha_0}{\alpha_n} I - \frac{\alpha_1}{\alpha_n} A  \cdots - \frac{\alpha_{n-1}}{\alpha_n} A^{n-1}.
\]
De fa\c{c}on similaire, on montre le cas $k>n$ par r\'ecurrence, utilisant $0 = A^{k-n} p_A(A)$.

(ii). Si $A$ est inversible alors $\det(A) \neq 0$. Donc puisque $p_A(A) = 0$ on obtient que
\[
  I = -\frac{\alpha_1}{\alpha_0} A  \cdots -\frac{\alpha_{n-1}}{\alpha_0}
A^{n-1} -\frac{\alpha_n}{\alpha_0} A^n = A \Big( -\frac{\alpha_1}{\alpha_0} I  \cdots
-\frac{\alpha_{n-1}}{\alpha_0} A^{n-2} -\frac{\alpha_n}{\alpha_0} A^{n-1} \Big)
\]
et donc $A^{-1} = -\frac{\alpha_1}{\alpha_0} I  \cdots
-\frac{\alpha_{n-1}}{\alpha_0} A^{n-2} -\frac{\alpha_n}{\alpha_0} A^{n-1}$.
\end{proof}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes"
%%% End:
