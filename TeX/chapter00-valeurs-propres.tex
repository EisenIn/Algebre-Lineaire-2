\chapter{Valeurs propres}
\label{cha:valeurs-propres-et}


\section{Valeurs propres et vecteurs propres}
\label{sec:valeurs-propres-et}

\begin{definition}
  \label{def:16}
  Soit $V$ un espace vectoriel sur un corps $K$ et $f \colon V ⟶V$ un endomorphisme. Un \emph{vecteur propre} de $f$  associé à la \emph{valeur propre} $λ ∈K$ est un vecteur $v ≠ 0$ de $V$ tel que $f(v) = λ\,v$.
\end{definition}

\begin{example}
  \label{exe:23}
  Soit $f：V⟶V$, l'endomorphisme $f(v) = 0$ pour tous $v ∈V$. Alors tous $0≠v ∈V$ est un vecteur propre associé à $λ=0$. 
\end{example}


\begin{lemma}
  \label{lem:4}
  Soit $B = \{v_1,\dots,v_n\}$ une base de $V$ et $A ∈ K^{n×n}$ la matrice de l'endomorphisme $f : V ⟶V$ relatif à $B$. La matrice $A$ est une matrice diagonale, c'est à dire $A$ est de la forme
  \begin{displaymath}
    A =
    \begin{pmatrix}
      λ_1  \\
         & \ddots \\
         & & λ_n
    \end{pmatrix},
  \end{displaymath}
si et seulement si $v_i$ est un vecteur propre associé à la valeur propre $λ_i$ pour tout $i=1,\dots,n$.
\end{lemma}

\begin{proof}
  Pour $v ∈V$ soit $[v]_B ∈K^n$ le vecteur des coordonnées de $v$ relatif à $B$. L'application $φ: V ⟶ K^n$, $φ(x) = [x]_B$ est un isomorphisme.  On a $[f(v_i)]_B = A \,  [v_i]_B$ pour $i=1,\dots,n$.
Supposons que $\{v_1,\dots,v_n\}$ est une base de vecteurs propres. 
  Si $[v_i]_B = e_i$, et $f(v_i) = λ_i v_i$ alors
    \begin{displaymath}
      λ_i ⋅ e_i = A \, e_i, \text{ pour } i ∈\{1,\dots,n\},
    \end{displaymath}
    c.à.d. que $A$ est une matrice diagonale.

La direction inverse est analogue. 
\end{proof}


\begin{definition}
  \label{def:39}
  Un endomorphisme $f ：V ⟶ V$ pour lequel existe une base de $V$ composée de vecteurs propres est \emph{diagonalisable}. 
\end{definition}


\begin{definition}
  \label{def:40}
  Soit $A ∈ K^{n ×n}$ une matrice.
  Un \emph{vecteur propre} de $A$ associé à la \emph{valeur propre} $λ ∈K$ est un vecteur propre de l'endormophisme  $f(x) = Ax$ de $K^n$.
\end{definition}




\begin{example}
 \begin{enumerate}
 \item Soit $A = \left(\begin{array}{cc}
1 & 0 \\
0 & 0
\end{array}
\right) \in ℝ^{2 ×2}$. Alors
\begin{itemize}
 \item $v_1 = \left( \begin{array}{c} 1 \\ 0 \end{array} \right)$ est un vecteur propre associ\'e \`a la valeur propre $\lambda_1 = 1$,
 \item $v_2 = \left( \begin{array}{c} 0 \\ 1 \end{array} \right)$ est un vecteur propre associ\'e \`a la valeur propre $\lambda_2 = 0$,
 \item $v_3 = \left( \begin{array}{c} 1 \\ 1 \end{array} \right)$ n'est pas un vecteur propre.
\end{itemize}
\item Soit $A = \left(\begin{array}{cc}
\cos \phi & \sin \phi \\
-\sin\phi & \cos \phi
\end{array}
\right) \in ℝ^{2 ×2}$ pour $\phi \in ℝ$. \begin{itemize}
\item
Si $\phi\not=k\pi$, $k\inℕ$, alors $A$ n'a pas de valeur propre (r\'eelle).
\item Si $\phi = (2k+1)\pi$, $k\in ℕ$, alors $A =
\left(\begin{array}{cc}
-1 & 0 \\
0 & -1
\end{array}
\right)$ a une valeur propre $\lambda = -1$ et tous les vecteurs non-nuls $x\in ℝ^2$ sont des vecteurs propres associ\'es \`a $\lambda$.
\item Si $\phi = 2k \pi$, $k\in ℕ$, alors $A =
\left(\begin{array}{cc}
1 & 0 \\
0 & 1
\end{array}
\right)$ a une valeur propre $\lambda = 1$ et encore tous les vecteurs non-nuls $x\in ℝ^2$ sont des vecteurs propres associ\'es \`a $\lambda$.
\end{itemize}
On va voir que si on consid\`ere $A$ comme une matrice complexe, alors on a toujours les valeurs propres $\cos \phi + \iunit \sin \phi$ et $\cos \phi - \iunit \sin \phi$.
\end{enumerate}
\end{example}

\begin{lemma}
  \label{lem:21}
  Un vecteur $v ∈ V ⧹\{0\}$ est un vecteur propre de $f：V ⟶V$  associé à la valeur propre $λ ∈ K$ si et seulement si $v ∈ \ker(f - λ ⋅ \Id)$.
\end{lemma}



Rappel: L'endomophisme $\Id ： V ⟶V$ défini comme $\Id(v) = v$ pour tous $v∈ V$  est appelé l'\emph{identité}.

\begin{definition}
  \label{def:1}
  Soit $λ$ une valeur propre de l'endomorphisme $f：V ⟶V$. Le sous espace $E_λ$ de $V$, défini comme
  \begin{displaymath}
    E_λ = \ker(f - λ ⋅ \Id)
  \end{displaymath}
  est l'espace propre de $f$ associé à $λ$. La dimension de $E_λ$ est la multiplicité géométrique de $λ$.
\end{definition}

\begin{lemma}
  \label{elem:1}
  Soient $v_1,\dots,v_r ∈V$ des vecteurs propres, associés aux valeurs propres $λ_1,\dots,λ_r$ distinctes (c'est à dire $λ_i ≠ λ_j$ pour $i≠j$), alors  $\{v_1,\dots,v_r\}$ est un ensemble libre.
\end{lemma}

\begin{proof}
  Supposons que le théorème soit faux et soit $r≥1$ minimal, tel qu'il existent des vecteurs propres $v_1,\dots,v_r ∈V$  associés aux valeurs propres $λ_1,\dots,λ_r$ qui sont linéairement dépendants. Des que $v_i ≠0$ alors $r>1$.
  Considérons une combinaison linéaire non triviale
  \begin{equation}
    \label{eq:35}
    α_1 v_1 + \cdots + α_r v_r = 0.
  \end{equation}
  Des que \eqref{eq:35} est un contre exemple minimal, on  $α_i≠0$ pour tous $i$. Nous pouvons supposer que $λ_r ≠0$. Autrement, on réarrange~\eqref{eq:35}. 

  Si on applique $f$ à l'expression \eqref{eq:35} on obtient
  \begin{displaymath}
    λ_1 α_1 v_1 + \cdots + λ_rα_r v_r = 0
  \end{displaymath}
  et en divisant par $λ_r$
  \begin{equation}
    \label{eq:37}
    (λ_1/λ_r) α_1 v_1 + \cdots + α_r v_r = 0.
  \end{equation}

  On soustrait \eqref{eq:37} de \eqref{eq:35} et on obtient

  \begin{displaymath}
    (1- λ_1/λ_n)α_1 v_1 + \cdots + (1- λ_{r-1}/λ_r)α_{r-1} v_{r-1}
  \end{displaymath} Ceci est en contradiction avec la minimalité de $r$.
\end{proof}


\begin{corollary}
  \label{eco:1}
   Soit $f ：V ⟶V$ un endomorphisme d'un espace vectoriel $V$ sur $K$ de dimension $n ∈ ℕ$ et soient $λ_1,\dots,λ_r$
  les valeurs propres différentes de $f$
  et soient $n_1,\dots,n_r$
  leurs multiplicités géométriques respectives. Soient
  $B_i= \{v_1^{(i)},\dots,v_{n_i}^{(i)}\}$
  des bases de $E_{λ_i}$ 
  respectivement, pour $i=1,\dots,r$. Alors
  \begin{displaymath}
    \{ v_1^{(1)},\dots,v_{n_1}^{(1)},v_1^{(2)},\dots,v_{n_2}^{(2)},\cdots,v_1^{(r)},\dots,v_{n_r}^{(r)} \}
  \end{displaymath}
est un ensemble libre. L'application $f$ est diagonalisable si et seulement si
\begin{displaymath}
  n_1 + \cdots + n_r =n.
\end{displaymath}
\end{corollary}
\begin{proof}
  Soit la combinaison linéaire 
  \begin{displaymath}
    ∑_{i=1}^r ∑_{j=1}^{n_i} α_{ij} v^{(i)}_j = 0.
  \end{displaymath}
  Remarquons que les vecteurs $ ∑_{j=1}^{n_i} α_{ij} v^{(i)}_j $ appartiennent à $E_{\lambda_i}$ pour tout $i$. Autrement dit, ce sont des vecteurs propres associés à des valeurs propres distinctes et dont la somme est nulle. Le lemme~\ref{elem:1} garantit donc que tous les vecteurs soient nuls. Par suite, $ ∑_{j=1}^{n_i} α_{ij} v^{(i)}_j $ et les $α_{ij}$ sont tous égaux à zéro car les $v_1^{(i)},\dots,v_{n_i}^{(i)}$ sont linéairement indépendants. Ça démontre que
   \begin{displaymath}
    \{ v_1^{(1)},\dots,v_{n_1}^{(1)},v_1^{(2)},\dots,v_{n_2}^{(2)},\cdots,v_1^{(r)},\dots,v_{n_r}^{(r)} \}	
  \end{displaymath} est un ensemble libre. En plus, si $n_1+\cdots+n_r=n$, $f$ est diagonalisable par définition car l'ensemble forme une base de $K^n$.

  À l'inverse, si $f$ est diagonalisable, et si $m_i$ dénote le nombre vecteurs propres en $E_{λ_i}$ dans la base consistant de vecteurs propres, alors $m_i ≤ n_i$, et on a
  \begin{displaymath}
    n = m_1 + \cdots + m_r ≤ n_1+ \cdots + n_r ≤n,
  \end{displaymath}
  et donc $n_1+\cdots + n_r =n$.
\end{proof}




Voici une marche à suivre afin de déterminer si $f：V ⟶V$ est diagonalisable ou non.

\begin{enumerate}
\item Déterminer les différentes $λ_1,\dots,λ_r ∈K$ tel que $\ker(f - λ \Id) ≠ \{ 0 \}$
\item Pour chaque $λ_i$ calculer une base $\{v_1^{(i)},\dots,v_{n_i}^{(i)}\}$ de $E_{λ_i}$.
\item $f$ est diagonalisable si et seulement si  $n_1+\cdots+n_r =n$.
\end{enumerate}





\subsection*{Exercices}

\begin{enumerate}
\item Une matrice $A ∈ K^{n ×n}$ est appelée \emph{diagonalisable},  si endomorphisme $φ：K^n ⟶K^n$ défini comme $φ(x) = Ax$ est diagonalisable. Démontrer que $A$ est diagonalisable, si et seulement s'il existe $U ∈ K^{n×n}$ inversible tel que $U^{-1} A U$ est une matrice diagonale. \label{item:18}
\end{enumerate}

\section{Le polynôme caractéristique}
\label{sec:le-polyn-caract}

Durant ce chapitre nous allons étudier les endomorphismes $f：V⟶V$ d'un espace vectoriel de dimension fini $n ∈ ℕ$.  Si  $B = \{v_1,\dots,v_n\}$ est une base de $V$, on a
\begin{displaymath}
  f(x) = \phi_B^{-1} (A_B \phi_B(x)),
\end{displaymath}
où $\phi_B$ est l'ismomorphisme $\phi_B \colon V \longrightarrow K^n$, $\phi_B(x) = [x]_B$ sont les coordonnées de $x$ par rapport à la base $B$. On a le diagramme suivant
\begin{displaymath}
  {
  \begin{CD}
    V     @>f>>  V\\
    @VV \phi_B V        @VV \phi_B V\\
    K^n     @>A \cdot x>>  K^n
  \end{CD}}
\end{displaymath}
Les colonnes de la matrice $A_B$ sont les coordonnées de $f(v_1),\dots,f(v_n)$ dans la base $B$. Si $B'$ est une autre base de $V$ on a
\begin{displaymath}
  [x]_{B'} = P_{BB'}[x]_B,
\end{displaymath}
où $P_{BB'}$ est la matrice de changement de base de $B$ en $B'$. Comme on a
\begin{displaymath}
  [f(v)]_{B'} = A_{B'} [v]_{B'} = A_{B'} P_{BB'}[v]_B
\end{displaymath}
et
\begin{displaymath}
  [f(v)]_{B'} =  P_{BB'}[f(v)]_B,
\end{displaymath}
on trouve
\begin{displaymath}
  [f(v)]_B =  P_{BB'}^{-1}A_{B'} P_{BB'}[v]_B \,\,\,\text{ pour tous } v ∈V.
\end{displaymath}
Et ça implique 
\begin{equation}
  \label{eq:36}
  A_{B} =  P_{BB'}^{-1} A_{B'}  P_{BB'}
\end{equation}
En particulier,
\begin{displaymath}
  \det(A_{B'}) = \det(A_B) 
\end{displaymath}
ce qui laisse nous définir le \emph{déterminant d'un endomorphisme} $f$ comme $\det(f)= \det(A_B)$. 



Clairement, $λ$ est une valeur propre de $f$ si et seulement si $λ$ est une valeur propre de $A_B$ et c'est le cas si et seulement si
\begin{equation}
  \label{eq:30}
  \det(A_B - λ I_n) = 0.
\end{equation}

Rappelons la formule de Leibniz pour le déterminant d'une matrice $B ∈ K^{n ×n}$
\begin{equation}
  \label{eq:31}
  \det(B)  = ∑_{π ∈S_n} \sign(π) ∏_{i=1}^n b_{iπ(i)}
\end{equation}
et si on regroupe les puissances de $λ$, on a
\begin{equation}
  \label{eq:32}
  \det(A_B - λI_n) = a_n λ^n + a_{n-1} λ^{n-1}+ \dots + a_1 λ+ a_0
\end{equation}
où $a_n,\dots,a_0 ∈K$. 

\begin{definition}
  \label{def:50}
  Le polynôme $\det(A_B - λI_n) ∈ K[λ]$ est le \emph{polynôme caractéristique} de $f$.   
\end{definition}

Remarquons que $\det(A_B) = \det(A - 0 ⋅ I_n)$, d'où $a_0 = \det(A_B)$.
L'expression \eqref{eq:32} est un polynôme avec indéterminée $λ$ et comme polynôme formel, est défini par la formule de Leibniz
\begin{displaymath}
p_A(λ) = \det(A - λ I_n) = ∑_{π ∈S_n} \sign(π) ∏_{i=1}^n (A - λ I_n)_{i,π(i)}.
\end{displaymath}
En tant que somme des polynômes $ \sign(π) ∏_{i=1}^n (A - λ I_n)_{i,π(i)}$, son degré est au plus $n$. Considérons la permutation triviale $\pi = \Id$ donnant le produit de degré $n$
\begin{displaymath}
  \sign(\Id) ∏_{i=1}^n (A - λ I_n)_{i\Id(i)} =  ∏_{i=1}^n (A_{ii} - λ),
\end{displaymath}
et en remarquons que toutes les autres permutations aboutissent à un produit au degré inférieur à $n-2$. Cela signifie en particulier que $a_n = (-1)^n$, et donc que le polynôme caractéristique est de degré $n$.

\begin{lemma}
  \label{lem:22}
Soit $p_A(λ) = a_0 + a_1 λ + \cdots + a_n λ^n$ le polynôme caractéristique de la matrice $A ∈ K^{n ×n}$. Alors, $a_0 = \det(A)$ et $a_n = (-1)^n$.
\end{lemma}


\begin{corollary}
  \label{co:10}
  Soit $V ≠ \{0\}$ un espace vectoriel de dimension fini sur $K = ℂ$, et $f: V → V$ un endomorphisme. Alors $f$ possède une valeur propre. 
\end{corollary}
\begin{proof}
  Soit $f(λ) ∈ ℂ[λ]$ le polynôme caractéristique de $f$ et $n$ la dimension de $V$. Le degré de $f$ est égal à $n≥1$, et donc $p(x)$ possède une racine $λ^* ∈ℂ$ (théorème fondamental de l'algèbre). Cette racine $λ^*$  est une valeur propre de $f$. 
\end{proof}


\begin{remark}
  \label{rem:6}
  Pour deux bases $B$ et $B'$, comme on a $A_{B} =  P_{BB'}^{-1} A_{B'}  P_{BB'}$, alors
  \begin{eqnarray*}
    \det(A_B - λI_n) & = & \det(P_{BB'}^{-1} A_{B'}  P_{BB'} - λP_{BB'}^{-1}I_n  P_{BB'}) \\
                     & = & \det(P_{BB'}^{-1}) \det(A_{B' }- λI_n) \det(P_{BB'}) \\
     & = & \det(A_{B' }- λI_n).
  \end{eqnarray*}
  La définition~\ref{def:50} ne dépend ainsi pas de la base choisie et a donc un sens.
\end{remark}




\begin{definition}
  \label{def:57}
 
  Soit  $λ ∈K$ une valeur propre de l'endomorphisme  $f: V ⟶V$. La \emph{multiplicité algébrique} de $λ$ est la multiplicité de $λ$ comme racine de $\det(f - λ \Id)$. 
\end{definition}


  \begin{proposition}
    \label{prop:6}
    Soit $f： V → V$ un endomorphisme et soit $λ ∈K$ une valeur propre de $f$. La multiplicité géométrique de $λ$ est au plus la multiplicité algébrique de $λ$. 
  \end{proposition}

  \begin{proof}
    Soit $m$ la multiplicité géométrique de $λ$ et soit  $\{v_1,\dots,v_m\}$  une base de $E_{λ}$. On la complète en une base
    \begin{displaymath}
B =     \{ v_1,\dots,v_m, w_1,\dots,w_{n-m}\} 
    \end{displaymath}
    de $V$.

    La matrice $A_B$ de l'endomorphisme $f$ dans la base $B$ est alors de la forme
    \begin{displaymath}
      A_B =
      \begin{pmatrix}
        λ I_m & C \\
        0 & D
      \end{pmatrix}
    \end{displaymath}
    où $C ∈ K^{m × n-m}$ et $D ∈ K^{(n-m) ×(n-m)}$. En effet, on a par définition $A_B[v_i]_{B} = [f(v_i)]_{B}$, et par conséquent $A_B e_i = \lambda e_i$, où $e_i$ est le $i$-ème vecteur canonique de dimension $n$.
    
    Lorsqu'on développe le déterminant d'une matrice en blocs comme $A_B$ grâce à la formule de Leibniz, seules les permutations envoyant $\{1, \dots, m\}$ et $\{m+1, \dots, n\}$ sur eux-même donnent un produit non nul. On peut alors diviser la somme en deux pour obtenir que le déterminant est exactement le produit des déterminants des blocs diagonaux.
    Le polynôme caractéristique $p(x) ∈ K[x]$ de $f$ est alors
    \begin{eqnarray*} p(x) & = &  
      \det   \begin{pmatrix}
        (λ -x) I_m & C \\
        0 & D-xI_{n-m}
      \end{pmatrix} \\
          & = & (λ -x)^m \det \left(D-xI_{n-m}\right). 
    \end{eqnarray*}
    La multiplicité algébrique de $λ$ est donc au moins $m$. 
  \end{proof}



\begin{theorem}[Théorème de diagonalisation]
  \label{thr:45}
  Soit $V$ un espace vectoriel sur $K$ de dimension $n$, $f:V⟶V$  un endomorphisme et $λ_1,\dots,λ_r ∈ K$ les valeurs propres distinctes de $f$.    Alors $f$ est diagonalisable si et seulement si 
  \begin{enumerate}[i)]
  \item le polynôme caractéristique $p_f(x)$ de $f$ décompose en facteurs linéaires, c'est-à-dire, \label{item:19} 
    \begin{displaymath}
      p_f(x) = (-1)^n ∏_{i=1}^r (x - λ_i )^{a_i}
    \end{displaymath}
    où $a_i$ est la multiplicité algébrique de $λ_i∈K$ pour tous $i$. 
    \item  $\dim(E_{λ_i}) = a_i$, pour tous $i=1,\dots,r$. C'est à dire, les multiplicités algébriques et géométriques sont les mêmes. \label{item:20}
  \end{enumerate}
\end{theorem}

\begin{proof}
  Supposons $f$ diagonalisable. Soit $B$ une base composée de vecteurs propres de $f$ et $A$ la matrice de $f$ associée à la base $B$. Le lemme~\ref{lem:4} implique que $A$ est diagonale et alors  $p_f(x) = \det(A - x \Id) = (-1)^n ∏_{i=1}^r (x - λ_i)^{a_i}$. La dimension de $E_{λ_i}$ est celle du noyau $\ker(A - λ_i I_n)$. Clairement $\dim(\ker(A - λ_i I_n)) = a_i$, et on a alors montré \ref{item:19}) et \ref{item:20}).


  Supposons maintenant que \ref{item:19}) et \ref{item:20}) tiennent. Soient $g_i$ les multiplicités géométriques des valeurs propres $λ_i$, $i=1,\dots,r$. Comme on a
  \begin{displaymath}
    \deg((-1)^n∏_{i=1}^r(x-λ_i)^{a_i}) =n,
  \end{displaymath}
  alors $g_1+ \cdots + g_r = n$ et $f$ est diagonalisable grâce au corollaire~\ref{eco:1}. 
\end{proof}



\begin{example}
  \label{exe:48}
  Le polynôme caractéristique de la matrice 
  \begin{displaymath}
    A =
    \begin{pmatrix}
      1 & 0 \\
      1 & 1 
    \end{pmatrix}
  \end{displaymath}
  est $(x - 1)^2$. La multiplicité géométrique de $λ = 1$ est $1$ et la multiplicité algébrique est $2$. La matrice n'est pas diagonalisable. 
\end{example}

\begin{example}
  \label{exe:30}
  Soit $f： ℝ^3 → ℝ^3$ donnée par
  \begin{displaymath}
      f(x) = Ax, \, \text{ où }      A =  \begin{pmatrix}
        0 & -1 & 1 \\
        -3 & -2 & 3 \\
        -2 & -2 & 3
      \end{pmatrix}      
    \end{displaymath}
    Pour la base canonique  $B = \{e_1,e_2,e_3\}$ de $ℝ^3$, on a $A_B =A$. Le polynôme caractéristique de $f$ est
    \begin{displaymath}
      p(x) = -x^3 + x^2 + x -1 = - (x-1)^2 (x+1). 
    \end{displaymath}
    Les valeurs propres de $f$ sont $λ_1 = 1$ et $λ_2 = -1$ et
    \begin{displaymath}
      \left\{
          \begin{pmatrix}
            1 \\ 0 \\1
          \end{pmatrix},
          \begin{pmatrix}
            0 \\ 1 \\ 1
          \end{pmatrix} \right\} \text{ et }  \left\{
          \begin{pmatrix}
            1 \\ 3 \\2
          \end{pmatrix} \right\}
    \end{displaymath}
    sont des bases de $E_{λ_1}$ et  $E_{λ_2}$  respectivement. Alors $f$ est diagonalisable et pour la base
    \begin{displaymath}
      B' =  \left\{
          \begin{pmatrix}
            1 \\ 0 \\1
          \end{pmatrix},
          \begin{pmatrix}
            0 \\ 1 \\ 1
          \end{pmatrix}, 
          \begin{pmatrix}
            1 \\ 3 \\2
          \end{pmatrix} \right\}   
    \end{displaymath}
    on a
    \begin{displaymath}
      A_{B'} =
      \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & -1 
      \end{pmatrix}
    \end{displaymath}
    et
    \begin{displaymath}
      P_{BB'} = \left(\begin{matrix}1 & 0 & 1\\0 & 1 & 3\\1 & 1 & 2\end{matrix}\right)^{-1}.
    \end{displaymath}
    On peut vérifier qu'on a bien
\begin{equation}
  A_{B} =  P_{BB'}^{-1} A_{B'}  P_{BB'}. 
\end{equation}

    
  \end{example}

  
\subsection*{Exercices}

\begin{enumerate}
\item Donner un exemple d'un corps fini $K$ et deux polynomes $p(x) ≠q(x) ∈ K[x]$ tel que $f_p=f_q$.
\end{enumerate}

\section{Matrices semblables}
\label{sec:matrices-semblables}

\begin{definition}
  \label{def:42}
  Deux matrices $A,B ∈K^{n×n}$ sont \emph{semblables}, s'il existe une matrice inversible $P ∈ K^{n ×n}$ tel que $A = P^{-1} ⋅B ⋅P$.  
\end{definition}
L'équation~\eqref{eq:36} montre que les matrices $A_B$ et $A_{B'}$ d'un endomorphisme $f：V⟶V$ sont semblables, pour $B$ et $B'$ deux bases de $V$.

\begin{definition}
  \label{def:43}
  L'ensemble des valeurs propres d'une matrice $A ∈ K^{n ×n}$ (resp. d'un endomorphisme $f：V ⟶V$) est appelé le \emph{spectre} de $A$ (resp. de $f$), noté $\spec(A)$ (resp. $\spec(f)$). 
\end{definition}

\begin{theorem}
  \label{thr:46}
  Soit $A ∈ K^{n ×n}$ une matrice et $P ∈ K^{n ×n}$ une matrice inversible.
  \begin{enumerate}[i)]
  \item Le spectre de $A$ et celui de $P^{-1}AP$ sont les mêmes.
  \item $v ∈ K^n$ est un vecteur propre de $A$ si et seulement si $P^{-1} v$  est un vecteur propre de $P^{-1}AP$.
  \item Les polynômes caractéristiques $p_A(x)$ et $p_{P^{-1}AP}(x)$ sont identiques. 
  \end{enumerate}
\end{theorem}


\section{Théorème de Hamilton-Cayley}
\label{sec:theoreme-de-hamilton}


Soit $A ∈ K^{n ×n}$ et $p(x) = a_0 + a_1x + \cdots + a_n x^n ∈ K[x] ⧹\{0\}$ un polynôme. On peut évaluer le polynôme en la matrice $A$ comme suit :
\begin{displaymath}
  p(A) = a_0 ⋅I_n + a_1 A + \cdots + a_n A^n ∈ K^{n ×n}. 
\end{displaymath}
Maintenant, soit $p_A(x)$ le polynôme caractéristique de $A$ et $v$ un vecteur propre de $A$ associé à la valeur propre $λ$. On voit
\begin{displaymath}
  p_A(A) ⋅v = a_0 v + a_1 λv + \cdots + a_n λ^n v = p_A(λ)v = 0 ⋅v = 0. 
\end{displaymath}
Dans le cas où $A$ est diagonalisable, il existe une base de vecteurs propres $\{ v_1,\dots,v_n \}$. On a alors $p_A(A) ⋅v_i = 0$ pour tous $i$, et donc $p_A(A) =0$. 

\begin{theorem}[Hamilton-Cayley] 
  \label{thr:47}
  Soit $A ∈ K^{n ×n}$ et $p_A(λ)$ le polynôme caractéristique de $A$, alors
  \begin{displaymath}
    p_A(A) =0.
  \end{displaymath}
\end{theorem}
\begin{proof}
 On écrit
  \begin{displaymath}
    \det(A - λI_n) I_n = \cof(A - λI_n)^T (A - λI_n),
  \end{displaymath}
  où $\cof(A - λI_n)$ est la comatrice de $(A - λI_n)$.
  
  En regroupant les coefficients de $λ^i$ dans $\cof(A - λI_n)^T$ on obtient
  \begin{displaymath}
    \cof(A - λI_n)^T = ∑_{i=0}^{n-1} λ^i B_i
  \end{displaymath}
  avec certaines matrices $B_i ∈K^{n ×n}$. Alors
  \begin{displaymath}
    a_0 I_n + a_1 λ I_n + \cdots + a_nλ^n I_n  = B_0A + ∑_{i=1}^{n-1}λ^i (B_iA - B_{i-1}) - λ^n B_{n-1},
  \end{displaymath}
  où $p_A(λ) = a_0+ \cdots + a_n λ^n$. Ceci implique
  \begin{equation}
    \label{eq:38}
    \begin{array}{rcl}
      a_0 I_n & = &  B_0A \\
      a_iI_n & = &  B_iA - B_{i-1} \text{ pour } i ∈  \{1,\dots,n-1\}\\
      a_n I_n & = & - B_{n-1}
    \end{array}
  \end{equation}
  ce que sont des équations de matrices en $K^{n ×n}$. Si on multiplie les matrices indicées par $i$ à droite par $A^i$ et qu'on somme les équations, on obtient $p_A(A)$ à gauche du signe d'égalité. À droite, on obtient une somme téléscopique égale à la matrice nulle.
\end{proof}





\begin{example}
Le polyn\^ome caract\'eristique de $A = \left( \begin{array}{cc} 1 & 1 \\ 0 & 2
\end{array} \right)$ est $p_A(t) = (1-t)(2-t)$. On a 
\[
 p_A(A) = (I_n-A)(2I_n-A) = 0 
\]
Pour la matrices $A = \left( \begin{array}{cc} 2 & 0 \\ 0 & 2 \end{array}
\right)$, on a bien sûr que $p_A(A) = 0$ pour $p_A(t) = (2-t)^2$. Cependant, il existe un polyn\^ome unitaire de degr\'e strictement inférieur tel que $q(A) = 0$, à savoir $q(t) = t-2$. 

\begin{definition}
  \label{def:44}
  Le polyn\^ome unitaire de degr\'e minimal parmi ceux qui annulent $A$ est appelé \emph{polyn\^ome minimal} de $A$.
\end{definition}

Nous examinerons de plus près le polyn{\^o}me minimal du chapitre~\ref{sec:polyn-les-lalg}.
\end{example}

Les résultats suivants donnent des utilisations typiques du théorème~\ref{thr:47}
\begin{corollary} Soit $A \in K^{n ×n}$.
\begin{enumerate}
\item[(i)] Toute puissance $A^k$ avec $k∈ℕ$ peut s'\'ecrire comme une combinaison lin\'eaire des puissances $I,A,A^2,\ldots,A^{n-1}$.
\item[(ii)] Si $A$ est inversible, alors l'inverse $A^{-1}$ peut s'\'ecrire comme une combinaison lin\'eaire des puissances $I,A,A^2,\ldots,A^{n-1}$.
\end{enumerate}
\end{corollary}

\begin{proof}
 (i). Trivialement, l'assertion est vraie pour $k = 0,1,\ldots,n-1$.
On montre le cas $k = n$. Par le théorème~\ref{thr:47}:
\[
 0 = p_A(A) = \alpha_0 I + \alpha_1 A  \cdots + \alpha_{n-1} A^{n-1} + A^n \quad
\Rightarrow \quad A^n = 
-\alpha_0 I - \alpha_1 A  \cdots - \alpha_{n-1} A^{n-1}.
\]
De fa\c{c}on similaire, on montre le cas $k>n$ par r\'ecurrence, utilisant $0 = A^{k-n} p_A(A)$.

(ii). Si $A$ est inversible alors $\alpha_0 = \det(A)$ est inversible. De $0 = p_A(A)$ on obtient que
\[
  I = -\frac{\alpha_1}{\alpha_0} A  \cdots -\frac{\alpha_{n-1}}{\alpha_0}
A^{n-1} -\frac{1}{\alpha_0} A^n = A \Big( -\frac{\alpha_1}{\alpha_0} I  \cdots
-\frac{\alpha_{n-1}}{\alpha_0} A^{n-2} -\frac{1}{\alpha_0} A^{n-1} \Big)
\]
et donc $A^{-1} = -\frac{\alpha_1}{\alpha_0} I  \cdots
-\frac{\alpha_{n-1}}{\alpha_0} A^{n-2} -\frac{1}{\alpha_0} A^{n-1}$.
\end{proof}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes"
%%% End:
