\chapter{Algèbre linéaire sur les entiers}
\label{cha:algebre-lineaire-sur}
 

Quand est-ce qu'un système d'équations linéaires possède une solution en nombre entiers ? Étant donnés $A ∈ℤ^{m × n}$ et $b ∈ℤ^m$, on aimerait décider si 
\begin{equation}
  \label{eq:40}
  A x = b, \, x ∈ ℤ^n 
\end{equation}
est résoluble et trouver toutes les solutions.



Une condition nécessaire pour que le système \eqref{eq:40} soit soluble est qu'il existe une solution $x ∈ℚ^n$, et donc que $\rank(A) = \rank(A|b)$. Aussi, on peut supprimer une ligne de $(A|b)$ qui est dans le span des autres lignes. On peut alors supposer que $A$ est de rang ligne plein, c'est-à-dire que $\rank(A) = m$. 

\begin{definition}
\label{def:59}
  Un nombre entier $d ∈ℤ$ \emph{divise} un nombre entier $a ∈ℤ$ s'il existe un nombre entier $x ∈ℤ$ tel que $d⋅x =A$. On note alors $d\mid A$, et si $d$ ne divise pas $A$ on écrit $d \nmid A$. 
\end{definition}
% Si $d \mid a$, alors s'il existe $x ∈ℤ$ tel que $d ⋅x =a$ et si $a \neq 0$ on peut conclure $d ≤ |a|$, parce que $|a| = |d| ⋅|x|$. 
\begin{definition}
  \label{def:45}
  Un nombre $d ∈ℤ$ est un diviseur commun de $a∈ℤ$ et $b ∈ℤ$, si $d \mid a$ et $d \mid b$. Si $\max\{|a|,|b|\} ≥1$, l'ensemble des diviseurs commun de $a$ et $b$ est un ensemble fini. Dans ce cas, on dénote le \emph{plus grand diviseur commun} de $a$ et $b$ par $\gcd(a,b)$. 
\end{definition}


\begin{theorem}
  \label{thr:48}
  Soient $a,b ∈ℤ$ et $\max\{|a|,|b|\} ≥1$. On a
  \begin{displaymath}
    \gcd(a,b) = \min \{ x ⋅a + y ⋅ b： x,y ∈ℤ,  x ⋅a + y ⋅ b≥1\}.
  \end{displaymath}
\end{theorem}

\begin{proof}
  Soit $d$ un diviseur commun de $a$ et $b$. Alors il existe $x^*, y^* ∈ℤ$ tel que $a = d⋅x^*$ et $b = d ⋅y^*$. Si $x ⋅a + y ⋅ b≥1$, où $x,y ∈ℤ$, alors
  \begin{displaymath}
    x ⋅a + y ⋅ b = (x ⋅x^* + y ⋅ y^*)  d ≥ |d|. 
  \end{displaymath}
  Par conséquent, on a  $d \le \min\{ x ⋅a + y ⋅ b： x,y ∈ℤ,  x ⋅a + y ⋅ b≥1\}$.
 Montrons que $\min\{ x ⋅a + y ⋅ b： x,y ∈ℤ,  x ⋅a + y ⋅ b≥1\}$ est un diviseur commun de $a$ et $b$. Supposons que $\min \nmid a$. Alors
 la  division avec reste implique l'existence de $q,r ∈ℤ$ tels que  
  \begin{displaymath}
    a = q ⋅ \min + r \quad \text{ et } \quad 1 \leq r < \min.
  \end{displaymath}
  Soient $x,y$ les entiers qui vérifient $\min = x ⋅a + y ⋅b$, alors
  \begin{displaymath}
    1 ≤ r = a - q ⋅ (x ⋅a + y ⋅b) = (1-q⋅x) a - qy ⋅b.
  \end{displaymath}
  Or $r$ est strictement plus petit que $\min$, ce qui est absurde. Il suit donc que $\min \mid a$ et, de façon analogue, $\min \mid b$.
  Aussi, on a montré que pour tout diviseur commun $d$ de $a$ et $b$, $\min\{ x ⋅a + y ⋅ b： x,y ∈ℤ,  x ⋅a + y ⋅ b≥1\}\geq d$ et donc que $\min\{ x ⋅a + y ⋅ b： x,y ∈ℤ,  x ⋅a + y ⋅ b≥1\}= \gcd(a,b)$
  
\end{proof}



\begin{corollary}
  \label{co:5}
  Soient $a,b ∈ℤ$ et $\max\{|a|,|b|\} ≥1$. Le $\gcd(a,b)$ est le diviseur commun  positif qui est divisé par chaque diviseur commun de $a$ et $b$. 
\end{corollary}

Pour calculer le plus grand diviseur commun de $a$ et $b$ on peut utiliser l'algorithme d'Euclide. Soient $a_0≥a_1 ∈ℤ$ pas tout les deux nuls. Si $a_1 = 0$, alors
\begin{displaymath}
\gcd(a_0,a_1) =   a_0. 
\end{displaymath}
Autrement, on applique la division avec reste
\begin{displaymath}
  a_0 = q_1 a_1 + a_2, 
\end{displaymath}
où $q_1,a_2 ∈ℤ$ et $0 ≤ a_2<a_1$. Un nombre entier $d ∈ℤ$ est un diviseur commun de $a_0$ et $a_1$ si et seulement si $d$ est un diviseur commun de $a_1$ et $a_2$. L'algorithme d'Euclide est le procédé de calculer la suite $a_0,a_1,a_2,\dots,a_{k-1},a_k ∈ℤ$  où $a_{k-1}>0$, $a_k=0$ et 
\begin{displaymath}
  a_{i-1} = q_i a_i + a_{i+1} 
\end{displaymath}
est le résultat de la division avec reste de $a_{i-1} $ par $a_i$. 

\begin{example}
  \label{exe:25}
  On calcule le plus grand diviseur commun de $a_0 = 52$ et $a_1=22$:
  \begin{displaymath}
    52 =   2 ⋅ 22 + 8, \quad 22 = 2 ⋅ 8  + 6, \quad 8 = 1 ⋅ 6 +2,\quad 6 = 3 ⋅2 + 0. 
  \end{displaymath}
  La suite est alors $a_{0}= 52, a_{1}= 22, a_{3} = 8, a_{4} = 6, a_{5} = 2, a_{6} = 0$. Ainsi $\gcd(52,22) = 2$. 
\end{example}

Le calcul des suites $a_i$ et $q_i$ donne aussi une représentation $\gcd(a_0,a_1) = x ⋅a_0 + y ⋅a_1$, $x,y ∈ℤ$. En effet
\begin{displaymath}
  \begin{pmatrix}
    a_{i} \\  a_{i+1} 
  \end{pmatrix}
  =
  \begin{pmatrix}
    0 & 1 \\
    1 & -q_i
  \end{pmatrix}
  \begin{pmatrix}
     a_{i-1} \\  a_{i}
   \end{pmatrix}
\end{displaymath}
et alors
\begin{displaymath}
  \begin{pmatrix}
    a_{k-1} \\ a_k
  \end{pmatrix} =
  \begin{pmatrix}
    0 & 1 \\
    1 & -q_{k-1}
  \end{pmatrix} \cdots
  \begin{pmatrix}
    0 & 1 \\
    1 & -q_{1}
  \end{pmatrix}
  \begin{pmatrix}
    a_0 \\ a_1
  \end{pmatrix}.
\end{displaymath}
\begin{example}
  \label{exe:50}
  On continue l'exemple~\ref{exe:25}.
  \begin{eqnarray*} 
    \begin{pmatrix}
      2 \\ 0
    \end{pmatrix} & = & 
    \begin{pmatrix}
      0 &1 \\
      1 & -3
    \end{pmatrix}
    \begin{pmatrix}
      0 &1 \\
      1 & -1
    \end{pmatrix}
    \begin{pmatrix}
      0 &1 \\
      1 & -2
    \end{pmatrix}
    \begin{pmatrix}
      0 &1 \\
      1 & -2
    \end{pmatrix}
    \begin{pmatrix}
     5 \\ 22
    \end{pmatrix} \\
   &  = & 
  \begin{pmatrix}
    3 & -7 \\
    -11 & 26 
  \end{pmatrix}
  \begin{pmatrix}
    52 \\22
  \end{pmatrix}
  \end{eqnarray*}
  Alors $2 = \gcd(52,22) = 3 ⋅52 -7 ⋅22$. 
\end{example}

Nous pouvons donc résoudre le problème~\eqref{eq:40} dans le cas où $m=1$ et $n=2$.

\begin{theorem}
  \label{thr:49}
  Soient $a,b ∈ℤ$ pas tous les deux nuls et $c ∈ℤ$. L'équation
  \begin{equation}
    \label{eq:41}
    x ⋅a + y ⋅b = c, \, x,y ∈ℤ
  \end{equation}
  possède une solution si et seulement si $\gcd(a,b) \mid c$. 
\end{theorem}
\begin{proof}
  Soient $x',y' ∈ℤ$ tel que $x' a + y'b = \gcd(a,b)$. Si $\gcd(a,b) \mid c$ alors il existe un $z ∈ℤ$ tel que $z ⋅\gcd(a,b) = c$ et $z x' a + z y'b = c$ est une solution en nombre entiers de~\eqref{eq:41}.

  S'il existe une solution de~\eqref{eq:41}, alors chaque diviseur commun de $a$ et $b$ est aussi un diviseur de $c$. 
\end{proof}

\section*{Exercices}


\begin{enumerate}
\item Démontrer le Corollaire~\ref{co:5}.
\item Soient $n≥2$ et $a_1,\dots,a_n∈ ℤ$ pas tous égaux à zéro. On définit $\gcd(a_1,\dots,a_n)$ comme étant le plus grand diviseur commun de $a_1,\dots,a_n$. Montrer: 
  \begin{enumerate}[i)]
    \item  $\gcd(a_1,\dots,a_n) =  \min\{x_1a_1+ \cdots + x_n a_n ： x_1a_1+ \cdots + x_n a_n≥1, \, x_i ∈ℤ, \, i=1,\dots,n\}$. 
  \item $\gcd(a_1,\dots,a_n) = \gcd(\gcd(a_1,a_2), a_3, \dots, a_n)$ pour $n≥3$. 
  \end{enumerate}
\item Soit $a_0≥a_1≥\dots≥a_k=0$ la suite calculée par l'algorithme d'Euclide. Montrer $a_{i-1} ≥ 2⋅ a_{i+1}$ et conclure  que $k ≤2 ⋅ \log_2(a_0)+1$.  
\end{enumerate}



\section{La forme normale d'Hermite}
\label{sec:la-forme-normale-1}

Maintenant on s'occupe du problème~\eqref{eq:40} où $A ∈ ℤ^{m ×n}$ et $b ∈ℤ^m$ et $\rank(A) = m$.

\begin{lemma}
  \label{lem:23}
  Soit $A ∈ℤ^{n ×n}$ une matrice inversible (sur $ℚ$), alors $A^{-1} ∈ ℤ^{n ×n}$ si et seulement si $\det(A) = \pm 1$. 
\end{lemma}

\begin{proof}
  Supposons que $A^{-1} ∈ℤ^{n ×n}$. Alors $1 = \det(I_n)  = \det(A^{-1}) \det(A)$. Les deux facteurs $\det(A^{-1})$ et $ \det(A)$ sont des nombres entiers. Les seul diviseurs de $1$ en nombre entiers sont $1$ et $-1$.

  Réciproquement, si $\det(A) = \pm 1$, on a
  \begin{displaymath}
    A^{-1} = \mathrm{ad}(A) / \det(A) ∈ℤ^{n ×n}. 
  \end{displaymath}
  où $\mathrm{ad}(A) ∈ ℤ^{n ×n}$ est la matrice complémentaire de $A$. On se rappelle que $(\mathrm{ad}(A))_{ij} = (-1)^{i+j}\det(A_{ji})$ où $A_{ji}∈ℤ^{(n-1)×(n-1)}$ est la matrice qu'on obtient de $A$ en supprimant la $j$-ème ligne et $i$-ème colonne.
  \end{proof}

  \begin{definition}
    \label{def:46}
    Une matrice $U ∈ℤ^{n ×n}$ telle que $\det(U) = \pm 1$ est appelée  \emph{unimodulaire}.
  \end{definition}

  \begin{remark}
    Soit $U ∈ℤ^{n ×n}$  une matrice unimodulaire. 
    Un $x^* ∈ ℤ^n$ est une solution du problème~\eqref{eq:40} si et seulement $U^{-1} x^*∈ ℤ^n$ est une solution du problème
    \begin{equation}
      \label{eq:42}
      A U x = b, \, x ∈ℤ^n. 
    \end{equation}
  \end{remark}
  %
L'idée est maintenant de trouver une matrice unimodulaire $U ∈ℤ^{n ×n}$ telle que
\begin{equation}
  \label{eq:44}
  A ⋅ U = [H | 0]
\end{equation}
où
\begin{displaymath}
  H =
  \begin{pmatrix}
    h_{11} \\
    h_{21} & h_{22}\\
    &  & \ddots \\
    h_{m1} & \hdots & \hdots & h_{mm}
  \end{pmatrix}
\end{displaymath}
est une matrice triangulaire. Le problème~\eqref{eq:40} est alors soluble si et seulement si
$H^{-1} b ∈ℤ^n$.

\begin{definition}
  \label{def:47}
  Soit $A ∈ ℤ^{m ×n}$ une matrice. Une \emph{opération élémentaire unimodulaire} est l'une des trois opérations suivantes
  \begin{enumerate}[i)]
    \item Multiplier une colonne par $-1$.  \label{item:21}
    \item Échanger deux colonnes de $A$.  \label{item:22}
    \item Additionner un multiple entier d'une colonne de $A$ à une autre colonne de $A$. \label{item:23}
  \end{enumerate}
\end{definition}



\begin{example}
  \label{exe:27}
  Une suite d'opérations élémentaire unimodulaire sur $A$ correspond à la multiplication $A⋅U$ où $U ∈ℤ^{n ×n}$ est une matrice unimodulaire.
Soit 
  \begin{displaymath}
    A =
    \begin{pmatrix}
      3 & 6 & 2 \\
      11 & 5 & 7
    \end{pmatrix}. 
  \end{displaymath}
  Échanger les colonnes $1$ et $2$ correspond à la multiplication à droite de $A$ avec la matrice unimodulaire 
  \begin{displaymath}
    \begin{pmatrix}
    0& 1 & 0 \\
    1 & 0 & 0 \\
    0 & 0 & 1
      
    \end{pmatrix}.
  \end{displaymath}
  \begin{displaymath}
     \begin{pmatrix}
      6  & 3& 2 \\
       5 & 11 & 7
     \end{pmatrix} = A ⋅
     \begin{pmatrix}
       0& 1 & 0 \\
       1 & 0 & 0 \\
       0 & 0 & 1
     \end{pmatrix}
   \end{displaymath}
   Additionner $-3$ fois la colonne $3$ sur la colonne $1$ est la multiplication à droite de $A$ avec la matrice unimodulaire 
   \begin{displaymath}
     \begin{pmatrix}       
     0 & 1 & 0\\ 
     1 & 0 & 0 \\
     -3 & 0 & 1
   \end{pmatrix}
 \end{displaymath} 
   \begin{displaymath}
     \begin{pmatrix}
      0  & 3& 2 \\
      -16 & 11 & 7
    \end{pmatrix} = A ⋅  \begin{pmatrix}
      
     0 & 1 & 0\\
     1 & 0 & 0 \\ 
     -3 & 0 & 1
   \end{pmatrix}
 \end{displaymath}
\end{example}


\begin{example}
  \label{exe:28}
  Est-ce que le système
  \begin{equation}
    \label{eq:43}
     \begin{pmatrix}
      3 & 6 & 2 \\
      11 & 5 & 10
    \end{pmatrix} x =
    \begin{pmatrix}
      2 \\ 2
    \end{pmatrix}, x ∈ℤ^3
      \end{equation}
  possède une solution ?
  Soustrayons la colonne $3$ à la colonne $1$:
  \begin{displaymath}
     \begin{pmatrix}
      1 & 6 & 2 \\
      1 & 5 & 10
    \end{pmatrix}
  \end{displaymath}
  Ensuite, on soustrait six fois la colonne $1$ à la colonne $2$ et deux fois la colonne $1$ à la colonne $3$ :
 \begin{displaymath}
     \begin{pmatrix}
      1 & 0 & 0 \\
      1 & -1 & 8
    \end{pmatrix}
  \end{displaymath}
  Puis, on additionne huit fois la colonne $2$ à la colonne $3$:
  \begin{displaymath}
  \begin{pmatrix}
      1 & 0 & 0 \\
      1 & -1 & 0
    \end{pmatrix}. 
  \end{displaymath}      
  Le système \eqref{eq:43} se réduit finalement à résoudre \[   \begin{pmatrix}
      1 & 0 & 0 \\
      1 & -1 & 0
    \end{pmatrix} y = b, y \in \Z^3 \]
  
  où $y = U^{-1}x$ pour une matrice unimodulaire $U$ adéquate.
   On conclut donc qu'il possède une solution entière. En fait
    \begin{displaymath}
     \begin{pmatrix}
      3 & 6 & 2 \\
      11 & 5 & 10
    \end{pmatrix} x =
    b, x ∈ℤ^3
  \end{displaymath} est soluble pour tout $b ∈ℤ^2$.
\end{example}


\begin{lemma}
  \label{lem:24}
  Soit  $A ∈ℤ^{ m ×n}$ une matrice à coefficients entiers, alors il existe une matrice unimudulaire $U ∈ℤ^{ n ×n}$ telle que la première ligne de $AU$ est de la forme $(d,0,\cdots,0)$, où $d ∈ℤ$.
\end{lemma}

\begin{proof}

    Si la première ligne n'est pas de cette forme, et si elle possède seulement une
  composante qui n'est pas égale à zéro, on échange les colonnes de sorte que
  la matrice résultante soit de la forme souhaitée.
  
  Autrement, il existe deux indices de colonne $j_1\neq j_2$, tels
  que $a_{1j_1}\neq 0$ et $a_{1j_2} \neq 0$. On peut supposer, quitte à permutter les colonnes $j_1$ et $j_2$, que
  $|a_{1j_1}| ≥ |a_{1j_2}|$. La division avec reste nous donne des entiers $q ∈ℤ$ et
  $0 ≤r < |a_{1j_2}|$ tels que
  \begin{displaymath}
    a_{1j_1} = q ⋅ a_{1j_2} + r. 
  \end{displaymath}
  On applique l'opération unimodulaire: \emph{Soustraire $q$ fois la
    colonne $j_2$ à la colonne $j_1$}, ce qui a pour effet de remplacer $a_{1j_1}$ par $r$ et
   de laisser les autres composantes de la première ligne intactes. Comme
    \begin{displaymath}
      0 < |r|+ |a_{1j_2}|<  |a_{1j_{1}}|+ |a_{1j_2}|
    \end{displaymath}
    ce procédé ne peut être répété infiniment. Il existe alors une
    matrice unimodulaire qui transforme $A$ en une matrice dont la première
    ligne possède une seule composante non nulle. Un échange de
    colonnes adéquat donne la forme désirée.
  \end{proof}

  \begin{corollary}
    \label{co:9}
    Soit  $A ∈ℤ^{ m ×n}$ une matrice en nombre entiers. Alors il  existe une matrice unimudulaire $U ∈ℤ^{ n ×n}$ telle que $A ⋅U$ est de la forme~\eqref{eq:44}.
  \end{corollary}
  \begin{proof}
    On raisonne par récurrence sur $m$. Le cas $m=1$ suit directement du Lemme~\ref{lem:24}. Soit $m>1$. 
    Le Lemme~\ref{lem:24} implique qu'il existe une matrice unimodulaire $U_1 ∈ℤ^{n ×n}$ telle que
    \begin{displaymath}
      A ⋅ U_1 =
      \begin{pmatrix}
        d & 0 \cdots 0 \\
        a  & A'
      \end{pmatrix}
    \end{displaymath}
    où $d ∈ℤ$, $a ∈ ℤ^{m-1}$ et $A' ∈ ℤ^{(m-1) × (n-1)}$. Par l'hypothèse de récurrence, il existe une matrice unimudulaire $U_2 ∈ℤ^{(n-1) ×(n-1)}$ telle que $A' U_2$ est de la forme désirée. Clairement
      \begin{displaymath}
         \begin{pmatrix}
          1 & 0^T \\
          0 & U_2
        \end{pmatrix} ∈ℤ^{n ×n}
      \end{displaymath}
      est une matrice unimodulaire et 
      \begin{displaymath}
        A U_1
        \begin{pmatrix}
          1 & 0^T \\
          0 & U_2
        \end{pmatrix}
      \end{displaymath}
      est de la  forme~\eqref{eq:44}. 
  \end{proof}



  \begin{definition}
    \label{def:60}
    Une matrice $A ∈ℤ^{m ×n}$  est en \emph{forme normale d'Hermite}, si elle est de la forme \eqref{eq:44}, où $h_{ii}>0$ pour tout $1 ≤i≤ m$ et $0≤ h_{ij} < h_{ii}$ pour tout $1≤j<i≤m$. 
  \end{definition}
	
\begin{theorem}
  \label{thr:28}
    Soit  $A ∈ℤ^{ m ×n}$ une matrice en nombre entiers. Alors il  existe une matrice unimudulaire $U ∈ℤ^{ n ×n}$ telle que $A ⋅U$ est en \emph{forme normale d'Hermite}.
  \end{theorem}
  
  \begin{definition}
    \label{def:61}
    Soit $A \in \mathbb{Z}^{m\times n}$ et  $rang(A)=m$. L'ensemble  $\Lambda(A):=\left\{ Ax: x\in \mathbb{Z}^{n} \right\}$ est  un \emph{réseau entier généré}  de $A$. Une matrice  $B \in \mathbb{Z}^{m\times m}$ telle que  $\Lambda(A)=\Lambda(B)$ est appelée base de $\Lambda(A)$. 
  \end{definition}

  \begin{remark}
    Une  \emph{base} $B ∈ ℤ^{m ×m}$  de $Λ(A)$ est inversible comme matrice réelle. C'est à dire $\det(B) ∈ℤ \setminus \{ 0\}$. 
  \end{remark}
	
 \begin{corollary}
   \label{co:12}
    Chaque réseau entier possède une base.
  \end{corollary}


  % \begin{lemma}
  %   \label{lem:25}
  %   Soient $B_1,B_2 ∈ℤ^{m×m}$ deux matrices inversibles. Alors $Λ(A) = Λ(B)$ si et seulement s'il existe une matrice unimodulaire $U ∈ ℤ^{m ×m}$ telle que $B_1 ⋅U = B_2$. 
  % \end{lemma}

  % \begin{proof}
  %   On a $U ∈ℤ^{ n ×n}$ unimodulaire tq. $A ⋅ U = [H | 0]$ et $H$ est
  %   en forme normale de Hermite. Il est alors simple de remarquer que
  %   $\Lambda(A)=\Lambda(H)$. Dès lors $H$ est une base du réseau
  %   entier $Λ(A)$.
  % \end{proof}

  \begin{theorem}
    \label{thr:28}
    Soient $A,B \in \mathbb{Z}^{m\times m}$ en forme normale
    d'Hermite.  Alors $Λ(A) = Λ(B)$ si et seulement si $A = B$.
  \end{theorem}

 \begin{proof}
   Si $A = B$, alors $Λ(A) = Λ(B)$.


   Supposons alors que $\Lambda(A) =\Lambda(B)$.  Maintenant on montre
   qui si $A\neq B$ alors $\Lambda(A) \neq \Lambda(B)$.  On note
   $A=\begin{pmatrix} a_{ 11 } & \quad & \quad \\ \quad & \ddots &
     \quad \\ a_{m1} & \quad & a_{ mm } \end{pmatrix}$ et
   $B=\begin{pmatrix} b_{ 11 } & \quad & \quad \\ \quad & \ddots &
     \quad \\ b_{m1} & \quad & b_{ mm } \end{pmatrix}$.  Soit $i$
   l'indice minimal tel que la $i$-ème ligne de $A$ et celle de $B$
   soient différentes. Alors
   $\exists j \in \left\{ 1,\dots ,i \right\}$ tel que
   $a_{ij} \neq b_{ij}$ et sans perte de généralité on a
   $a_{ij}>b_{ij}$. Clairement en notant $A_j$ ( resp. $B_j$) la
   $j$-ème colonne de $A$ (resp. $B$), on a
   $A_j - B_j = \begin{pmatrix} 0 \\ \vdots \\ 0\\ a_{ ij }-b_{ ij }
     \\ \vdots \end{pmatrix} \in \Lambda (A)$ avec
   $a_{ii}>a_{ij}-b_{ij}>0$.

   Il existe donc un vecteur entier $z ∈ℤ^n$ tel que
   $A_j - B_j = Az$. On montre aisément que les $i-1$ premières
   coordonées de $z$ doivent être nulles car aucun élément diagonal de
   $A$ ne l'est (ou, de manière équivalente, car $A$ et de rang
   plein). Or, en comparant la $i$-ème coordonnée, on trouve que
   $a_{ij} - b_{ij} = a_{ii} z_i$. Dès lors, $a_{ii}|a_{ij}-b_{ij}$ ce
   qui est une contradiction. 
 \end{proof}
  \begin{remark}
    \label{rem:5}
    Le Théorème~\ref{thr:28} nous permet de vérifier, pour
    $A ∈ℤ^{m × n_1}$ et $B ∈ℤ^{m × n_2}$ de rang ligne pleins, si
    $Λ(A) = Λ(B)$.  On calcule $(H_A|0)$ et $(H_B|0)$ les formes
    normales d'Hermite de $A$ et $B$. Comme $Λ(A) =Λ(H_A)$ et
    $Λ(B) = Λ(H_B)$, on a que $Λ(A) = Λ(B)$ si et seulement si
    $H_A = H_B$.
  \end{remark} 
  
  \begin{example}
    \label{exe:29}
    On va transformer
    $A = \left(\begin{matrix}4 & 6 & 10\\6 & 12 &
        9\end{matrix}\right)$ en forme normale d'Hermite afin de
    trouver toutes les solutions entières de
    \begin{equation}
      \label{eq:46}
      \left(\begin{matrix}4 & 6 & 10\\6 & 12 & 9\end{matrix}\right) x =
      \begin{pmatrix}
        6 \\ 3
      \end{pmatrix}, \, x ∈ ℤ^3. 
    \end{equation}
    
    \begin{equation}
      \label{eq:45}
      \begin{array}{cc}
        \left(\begin{matrix}4 & 6 & 10\\6 & 12 & 9\end{matrix}\right) &  
                                                                        \left(\begin{matrix}1 & 0 & 0\\0 & 1 & 0\\0 & 0 & 1\end{matrix}\right) \\

\left(\begin{matrix}4 & 2 & 2\\6 & 6 & -3\end{matrix}\right) &  
\left(\begin{matrix}1 & -1 & -2\\0 & 1 & 0\\0 & 0 & 1\end{matrix}\right) \\

\left(\begin{matrix}2 & 4 & 2\\6 & 6 & -3\end{matrix}\right) &
\left(\begin{matrix}-1 & 1 & -2\\1 & 0 & 0\\0 & 0 & 1\end{matrix}\right)\\

\left(\begin{matrix}2 & 0 & 0\\6 & -6 & -9\end{matrix}\right)&
\left(\begin{matrix}-1 & 3 & -1\\1 & -2 & -1\\0 & 0 & 1\end{matrix}\right)\\

\left(\begin{matrix}2 & 0 & 0\\6 & 3 & -9\end{matrix}\right) &
\left(\begin{matrix}-1 & 4 & -1\\1 & -1 & -1\\0 & -1 & 1\end{matrix}\right)\\

\left(\begin{matrix}2 & 0 & 0\\6 & 3 & 0\end{matrix}\right) &
\left(\begin{matrix}-1 & 4 & 11\\1 & -1 & -4\\0 & -1 & -2\end{matrix}\right)\\


\left(\begin{matrix}2 & 0 & 0\\0 & 3 & 0\end{matrix}\right) &
\left(\begin{matrix}-9 & 4 & 11\\3 & -1 & -4\\2 & -1 & -2\end{matrix}\right)\\
      \end{array}      
    \end{equation}

    L'ensemble des  solutions entières de~\eqref{eq:46} est 
    \begin{displaymath}
      \left\{ \left(\begin{matrix}-23\\8\\5\end{matrix}\right) + \left(\begin{matrix}11\\-4\\-2\end{matrix}\right) ⋅z ： z ∈ℤ\right\}
    \end{displaymath}
    
  \end{example}
  
  \begin{definition}
    \label{def:62}
    Soit $A \in \mathbb{Z}^{m \times n}$. Le \emph{noyau} de $A$ sur $\Z$ est défini par $ker_{\mathbb{Z}}(A) := \left\{ y \in \mathbb{Z}^n, Ay=0 \right\}  $.
  \end{definition}
  
  \begin{theorem}
    \label{thr:59}
    Soient $A,B \in \mathbb{Z}^{m \times m}$ en forme normale de Hermite avec $rang(A)=rang(B)=m$. Alors $\Lambda(A)=\Lambda(B) \Leftrightarrow \exists U\in \mathbb{Z}^{m \times m}$ unimodulaire telle que $B=AU$.
  \end{theorem}
  
  \begin{proof}
 Si $\Lambda(A)=\Lambda(B)$ alors $A=B⋅ P, P\in \mathbb{Z}^{m \times m}$ et  $B=A⋅Q, Q\in \mathbb{Z}^{m \times m}$. Alors on obtient $A=AQP$ ce qui implique $QP=I_m$ et donc on a bien $P,Q$ unimodulaires.

 Si $B=AU, U\in \mathbb{Z}^{m \times m}$ unimodulaire alors comme $U \mathbb{Z}^{m}= \mathbb{Z}^{m}$ on obtient immédiatement  $\Lambda(A)=\Lambda(B)$.
\end{proof}
\begin{definition}
  \label{def:48}
  Soient $A\in \mathbb{Z}^{m \times n}$ avec $rang(A)=m$ et
  $\Lambda(A)$ le réseau entier de $A$. Le \emph{déterminant} du
  réseau $\Lambda(A)$ est donné par $\det(\Lambda(A)):=|\det(B)|$ où
  $B \in \mathbb{Z}^{m \times m}$ est une base de $\Lambda(A)$
   \end{definition}
   
   \begin{remark}
    Le théorème~\ref{thr:59} assure que $|\det(B)|$ ne dépend pas du choix de $B$ et donc que $\det(\Lambda(A))$ a du sens.
    \end{remark}
  
\section*{Exercices}
\begin{enumerate}
\item Soit $A ∈ℤ^{m ×n}$ avec rang ligne plein. Le noyaux entier de $A$ est l'ensemble
  \begin{displaymath}
    \ker_ℤ(A) = \{x ∈ℤ^n ： Ax = 0\}. 
  \end{displaymath}
  Soit  $U ∈ℤ^{n ×n}$ une matrice unimodulaire telle que
  \begin{displaymath}
    A ⋅ U = (H | 0) 
  \end{displaymath}
  est la forme normale d'Hermite.
  Montrer que $\ker_ℤ(A) = \{ y_1 u_1 + \cdots + y_{n-m} u_{n-m} ： y_i ∈ℤ\}$ où $u_1,\dots,u_{n-m}$ sont les dernières $n-m$ colonnes de $U$. 
\end{enumerate}

\subsection*{La forme normale de Smith}
\label{sec:la-forme-normale-smith}

   \begin{theorem}
    \label{thr:28}
    Soit $A \in \mathbb{Z}^{m\times n}$, $A≠0$ alors il existent $ U \in \mathbb{Z}^{m\times m}$ et $V \in
    \mathbb{Z}^{n\times n}$ unimodulaires telle que
    \begin{equation}
      \label{eq:58}
    U⋅A⋅V = \begin{pmatrix}
      \delta _{ 1 } & \quad & \quad & \quad & \quad \\ \quad & \ddots
      & \quad & \quad & \quad \\ \quad& \quad& \delta _{ k } & \quad &
      \quad \\ \quad & \quad & \quad & \quad &\quad
    \end{pmatrix}, \quad \text{ avec } \delta_i \in
    \mathbb{N}_{\ge1} \text{ et } \delta_1| \cdots |\delta_k
  \end{equation}
  et les coefficients
    non spécifiés sont $0$. 
  \end{theorem}
  \noindent 
  La matrice~\eqref{eq:58} est appelée
  la \emph{forme normale de Smith} de $A$. 
\begin{proof}
  On raisonne par récurrence sur $\min\{m,n\}$. Si $\min\{m,n\}=1$, la forme normale de Hermite de $A$ ou son transposé est en forme normale Smith.

  Maintenant, soit  $\min\{m,n\}>1$. Soient  $ U \in \mathbb{Z}^{m\times m}$ et $V \in
  \mathbb{Z}^{n\times n}$ unimodulaires telle que la valeur absolue minimale des éléments non-zéro de la matrice $U⋅A ⋅V$ est minimale, alors tel que
  \begin{displaymath}
    \min\{ | (U⋅A ⋅V )_{i,j} | : (U⋅A ⋅V )_{i,j} ≠ 0, \, 1≤ i ≤ m, \, 1 ≤ j ≤ n\} 
  \end{displaymath} est minimal. 
  Soit cette valeur minimale  $d$. En échangeant  lignes et colonnes et en multipliant la  par $-1$ si nécessaire, on peut supposer que $d  = (U⋅A ⋅V )_{1,1}$.
  Tous composantes de la première  ligne de $U⋅A ⋅V$ sont des multiples de $d$. Autrement, si $(U⋅A ⋅V )_{1,j} = z$ où $z$ n'est pas un multiple de $d$, la division avec reste de $z$ par $d$ donne 
  \begin{displaymath}
    z = q ⋅ d + r, \, 0 < r < d. 
  \end{displaymath}
  Une opération élémentaire de colonne (soustraire $q$ fois colonne $1$ de colonne $j$) donne composante $i,j$ égal à $r$. Ceci est une contradiction à $d$ minimal. Également, $d$ divise toute composante de la première colonne de  $U⋅A ⋅V$. Alors on peut éliminer toute autre composante de la première ligne et colonne. Alors on peut supposer que
  \begin{equation}
      U⋅A ⋅V  =
      \begin{pmatrix}
        d & \\ 
          & B 
      \end{pmatrix}, \quad \text{ où }  B ∈ ℤ^{(m-1 ) × (n-1)}.  
    \end{equation}
    Maintenant, si $b_{i,j}$ n'est pas un multiple de $d$, on peut
    additionner la ligne $i+1$ de $U⋅A ⋅V$ sur la première
    ligne. Comme avant on obtient le reste de la division comme
    composante après une opération élémentaire de colonnes. Ceci
    démontre que $d ∈ ℕ_+$ divise toute composante de $B$.

    Par récurrence, $B$ possède une forme normale Smith et ses composantes sont tous des multiples de $d$. 
  
\end{proof} 


\subsection*{Sous groupes de $ℤ^n$} 
\label{sec:sous-groupes-de}

À partir de maintenant, on se donne une matrice $A\in \mathbb{Z}^{m\times n}$ avec $rang(A)=k$ et $k$ n'est pas forcément $m$.

\begin{definition} \label{def:63}
  Soit  $A\in \mathbb{Z}^{m\times n}$ alors $\Lambda(A)=\left\{ Ax ：x\in \mathbb{Z
    }^{n} \right\} $ est le \emph{réseau entier général} de $A$.
\end{definition}



\begin{theorem}
    \label{thr:28}
    Soit  $A\in \mathbb{Z}^{m\times n}$ avec $rang(A)=k$ alors $\exists B \in \mathbb{Z}^{m \times k}$ tq. $\Lambda(A)=\Lambda(B)$. $B$ est alors appelée une base générale de $\Lambda(A)$.
    \end{theorem}
    
    \begin{remark}
      $rang(A)=rang(B)=k$.
    \end{remark}
    
    \begin{proof}
      Supposons que les $k$ premières lignes de $A$ sont linéairement
      indépendantes.  Dès lors on a
      $A=\begin{pmatrix} A' \\ A'' \end{pmatrix}$ avec
      $A'\in \mathbb{Z}^{k \times n}$ et $rang(A')=k$ soit alors
      $U\in \mathbb{Z}^{n \times n}$ unimodulaire tq.
      \begin{displaymath}
        A' ⋅ U = [H \mid 0]
      \end{displaymath}
      ou
      $H \in \mathbb{Z}^{k \times k}$ est en forme normale de
      Hermite. Alors on peut se convaincre en raisonnant sur les rangs
      que $AU=\begin{pmatrix} H & 0 \\ C & 0 \end{pmatrix}$ où $C ∈ ℤ^{(m-k)×k}$. Dés lors
      on a
      \begin{eqnarray*}
        \Lambda(A) & = & A\mathbb{Z}^n \\
                   & = & A⋅U \, \mathbb{Z}^n \\
        & = & \left[\begin{matrix} H   \\
          C \end{matrix} \right]\mathbb{Z}^k \\
        & = & \Lambda\left(  \left[\begin{matrix} H   \\
          C \end{matrix} \right]  \right).
      \end{eqnarray*}      
    \end{proof}
    
    \begin{theorem}
    \label{thr:28}
    Soit $G$ un sous groupe de $\mathbb{Z}^n$ alors il existe $B \in \mathbb{Z}^{n \times k}$ avec $rang(B)=k$ et tq. $\Lambda(B)=G$ 
    \end{theorem}
    
    \begin{proof}
    Soit $(v_1,\dots,v_k) \in G^k$ tq.  $(v_1,\dots,v_k)$ est une base du sous espace  $\spa(G)⊆ ℝ^n$. Alors posons $B=(v_1\dots v_k) ∈ ℤ^{n ×k}$.  
    Si  $\Lambda(B)=G$ et c'est terminé. 
   Si  $\Lambda(B)\subsetneq G$ alors il existe $ v^* \in G-\Lambda(B)$. Soit alors $B^* \in \mathbb{Z}^{n \times k}$ une base générale du réseau général $G\supseteq \Lambda(v_1\dots v_k v^*)\supsetneq  \Lambda(B)$. Alors il existe $ U\in \mathbb{Z}^{k \times k}$ tq. $B=B^*U$ et on a nécessairement $|\det(U)| \in \mathbb{N} _{\ge 2}$. Dés lors on peut remarquer que $|\det({B^TB})|=\det(U)^2\times|\det(B^{*^{T}}B^*)|$ et donc $|\det({B^TB})|\le \frac { 1 }{ 4 } |\det({B^TB})|$ mais comme $|\det(B^{*^{T}}B^*)|\ge 1$ et on peut répéter ces opérations sur $B^*$ mais ce procédé ne peut pas continuer indéfiniment.
    \end{proof}
    
  
    
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes"
%%% End:
